{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "8658021d",
            "metadata": {},
            "source": [
                "# Comparison of Replay Strategies in pyCLAD\n",
                "\n",
                "This notebook compares the performance of `ReplayEnhancedStrategy` and `BalancedReservoirSamplingStrategy` from the `pyCLAD` library.\n",
                "The comparison is performed across four datasets: Energy, NSL-KDD, UNSW, and Wind.\n",
                "For each dataset, three different data scenarios are used: `random_anomalies`, `clustered_with_closest_assignment`, and `clustered_with_random_assignment`.\n",
                "\n",
                "The notebook is divided into three main parts:\n",
                "1.  **Setup**: Imports necessary libraries and defines the configuration for datasets, strategies, and output directories.\n",
                "2.  **Run Experiments**: Executes the experiments for each combination of dataset, scenario, and strategy, saving the results to JSON files.\n",
                "3.  **Analyze Results**: Loads the saved results, generates heatmaps for each experiment, and creates comparison heatmaps to visualize the performance difference between the two strategies."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "5c359695",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/Users/firepond/code/pyCLAD/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
                        "  from .autonotebook import tqdm as notebook_tqdm\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Setup complete.\n"
                    ]
                }
            ],
            "source": [
                "import pathlib\n",
                "import json\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import numpy as np\n",
                "import os\n",
                "\n",
                "\n",
                "import sys\n",
                "sys.path.append(\"../src/\")\n",
                "\n",
                "# Datasets\n",
                "from pyclad.data.datasets.unsw_dataset import UnswDataset\n",
                "from pyclad.data.datasets.nsl_kdd_dataset import NslKddDataset\n",
                "from pyclad.data.datasets.wind_energy_dataset import WindEnergyDataset\n",
                "from pyclad.data.datasets.energy_plants_dataset import EnergyPlantsDataset\n",
                "\n",
                "# Scenarios\n",
                "from pyclad.scenarios.concept_aware import ConceptAwareScenario\n",
                "\n",
                "from pyclad.metrics.continual.average_continual import ContinualAverage\n",
                "from pyclad.metrics.continual.backward_transfer import BackwardTransfer\n",
                "from pyclad.metrics.continual.forward_transfer import ForwardTransfer\n",
                "# Models\n",
                "from pyclad.models.adapters.pyod_adapters import LocalOutlierFactorAdapter\n",
                "\n",
                "# Strategies\n",
                "from pyclad.strategies.replay.replay import ReplayEnhancedStrategy\n",
                "from pyclad.strategies.replay.candi import CandiStrategy\n",
                "\n",
                "# Additional imports for replay strategies\n",
                "from pyclad.strategies.replay.buffers.adaptive_balanced import AdaptiveBalancedReplayBuffer\n",
                "\n",
                "from pyclad.strategies.replay.selection.random import RandomSelection\n",
                "\n",
                "# Callback and metrics\n",
                "from pyclad.callbacks.evaluation.concept_metric_evaluation import ConceptMetricCallback\n",
                "from pyclad.callbacks.evaluation.memory_usage import MemoryUsageCallback\n",
                "from pyclad.callbacks.evaluation.time_evaluation import TimeEvaluationCallback\n",
                "from pyclad.metrics.base.roc_auc import RocAuc\n",
                "from pyclad.output.json_writer import JsonOutputWriter\n",
                "import time\n",
                "\n",
                "# Configuration\n",
                "DATASETS = {\n",
                "    \"energy\": EnergyPlantsDataset,\n",
                "    \"nsl-kdd\": NslKddDataset,\n",
                "    \"unsw\": UnswDataset,\n",
                "    \"wind\": WindEnergyDataset,\n",
                "}\n",
                "\n",
                "DATASET_TYPES = [\n",
                "    \"random_anomalies\",\n",
                "    \"clustered_with_closest_assignment\",\n",
                "    \"clustered_with_random_assignment\",\n",
                "]\n",
                "\n",
                "max_buffer_size = 1000  # Maximum size for replay buffers  \n",
                "\n",
                "STRATEGIES = {\n",
                "    \"replay_enhanced\": lambda model: ReplayEnhancedStrategy(\n",
                "        model,\n",
                "        AdaptiveBalancedReplayBuffer(selection_method=RandomSelection(), max_size=max_buffer_size),\n",
                "    ),\n",
                "    \"candi\": lambda model: CandiStrategy(\n",
                "        model, max_buffer_size=max_buffer_size, threshold_ratio=0.5, warmup_period=2, resize_new_regime=True\n",
                "    ),\n",
                "}\n",
                "\n",
                "\n",
                "print(\"Setup complete.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "4f42f85d",
            "metadata": {},
            "source": [
                "### Run Experiments\n",
                "\n",
                "The following cell runs the experiments. It iterates through each dataset and dataset type, and for each, it runs both the `ReplayEnhancedStrategy` and the `BalancedReservoirSamplingStrategy`. The results are saved in the `comparison_results` directory.\n",
                "\n",
                "**Note:** This process can be time-consuming."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a73b19b9",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Running experiments for energy - random_anomalies\n",
                        "Fitting model on combined data of shape: (6000, 14)\n",
                        "Fitting model on combined data of shape: (7000, 14)\n",
                        "Fitting model on combined data of shape: (7000, 14)\n",
                        "Fitting model on combined data of shape: (6999, 14)\n",
                        "Fitting model on combined data of shape: (7000, 14)\n",
                        "Fitting model on combined data of shape: (7000, 14)\n",
                        "Fitting model on combined data of shape: (6996, 14)\n",
                        "Fitting model on combined data of shape: (6994, 14)\n",
                        "Fitting model on combined data of shape: (7000, 14)\n",
                        "Fitting model on combined data of shape: (6999, 14)\n",
                        "Lifelong Learning Metrics:\n",
                        "  ContinualAverage: 0.9515100654069768\n",
                        "  BackwardTransfer: -0.007986692506459949\n",
                        "  ForwardTransfer: 0.5807531209625323\n",
                        "  Time taken: 9.74 seconds\n",
                        "Fitting model with 3500 samples\n",
                        "Fitting model with 7000 samples\n",
                        "Fitting model with 7001 samples\n",
                        "Fitting model with 7000 samples\n",
                        "Fitting model with 7000 samples\n",
                        "Fitting model with 7004 samples\n",
                        "Fitting model with 7000 samples\n",
                        "Fitting model with 7004 samples\n",
                        "Fitting model with 7001 samples\n",
                        "Fitting model with 7000 samples\n",
                        "Lifelong Learning Metrics:\n",
                        "  ContinualAverage: 0.9543791985993658\n",
                        "  BackwardTransfer: -0.007277487080103372\n",
                        "  ForwardTransfer: 0.6118101057816537\n",
                        "  Time taken: 9.20 seconds\n",
                        "--------------------\n",
                        "Running experiments for energy - clustered_with_closest_assignment\n",
                        "Fitting model on combined data of shape: (6000, 14)\n",
                        "Fitting model on combined data of shape: (7000, 14)\n",
                        "Fitting model on combined data of shape: (7000, 14)\n",
                        "Fitting model on combined data of shape: (6999, 14)\n",
                        "Fitting model on combined data of shape: (7000, 14)\n",
                        "Fitting model on combined data of shape: (7000, 14)\n",
                        "Fitting model on combined data of shape: (6996, 14)\n",
                        "Fitting model on combined data of shape: (6994, 14)\n",
                        "Fitting model on combined data of shape: (7000, 14)\n",
                        "Fitting model on combined data of shape: (6999, 14)\n",
                        "Lifelong Learning Metrics:\n",
                        "  ContinualAverage: 0.9174757310997418\n",
                        "  BackwardTransfer: -0.011363472083794766\n",
                        "  ForwardTransfer: 0.7352470364322284\n",
                        "  Time taken: 9.49 seconds\n",
                        "Fitting model with 3500 samples\n",
                        "Fitting model with 7000 samples\n",
                        "Fitting model with 7001 samples\n",
                        "Fitting model with 7000 samples\n",
                        "Fitting model with 7000 samples\n",
                        "Fitting model with 7004 samples\n",
                        "Fitting model with 7000 samples\n",
                        "Fitting model with 7004 samples\n",
                        "Fitting model with 7001 samples\n",
                        "Fitting model with 7000 samples\n",
                        "Lifelong Learning Metrics:\n",
                        "  ContinualAverage: 0.9241207256080864\n",
                        "  BackwardTransfer: -0.00842901311472047\n",
                        "  ForwardTransfer: 0.7649941040333282\n",
                        "  Time taken: 9.21 seconds\n",
                        "--------------------\n",
                        "Running experiments for energy - clustered_with_random_assignment\n",
                        "Fitting model on combined data of shape: (6000, 14)\n",
                        "Fitting model on combined data of shape: (7000, 14)\n",
                        "Fitting model on combined data of shape: (7000, 14)\n",
                        "Fitting model on combined data of shape: (6999, 14)\n",
                        "Fitting model on combined data of shape: (7000, 14)\n",
                        "Fitting model on combined data of shape: (7000, 14)\n",
                        "Fitting model on combined data of shape: (6996, 14)\n",
                        "Fitting model on combined data of shape: (6994, 14)\n",
                        "Fitting model on combined data of shape: (7000, 14)\n",
                        "Fitting model on combined data of shape: (6999, 14)\n",
                        "Lifelong Learning Metrics:\n",
                        "  ContinualAverage: 0.9351974819630254\n",
                        "  BackwardTransfer: -0.007645076916964028\n",
                        "  ForwardTransfer: 0.6005363983209262\n",
                        "  Time taken: 9.58 seconds\n",
                        "Fitting model with 3500 samples\n",
                        "Fitting model with 7000 samples\n",
                        "Fitting model with 7001 samples\n",
                        "Fitting model with 7000 samples\n",
                        "Fitting model with 7000 samples\n",
                        "Fitting model with 7004 samples\n",
                        "Fitting model with 7000 samples\n",
                        "Fitting model with 7004 samples\n",
                        "Fitting model with 7001 samples\n",
                        "Fitting model with 7000 samples\n",
                        "Lifelong Learning Metrics:\n",
                        "  ContinualAverage: 0.943143222785176\n",
                        "  BackwardTransfer: -0.007317675941021921\n",
                        "  ForwardTransfer: 0.6344771542999672\n",
                        "  Time taken: 9.22 seconds\n",
                        "--------------------\n",
                        "Finished experiments for energy.\n",
                        "========================================\n",
                        "Running experiments for nsl-kdd - random_anomalies\n",
                        "Fitting model on combined data of shape: (352, 41)\n",
                        "Fitting model on combined data of shape: (2231, 41)\n",
                        "Fitting model on combined data of shape: (3852, 41)\n",
                        "Fitting model on combined data of shape: (3999, 41)\n",
                        "Fitting model on combined data of shape: (1926, 41)\n",
                        "Fitting model on combined data of shape: (1720, 41)\n",
                        "Fitting model on combined data of shape: (2575, 41)\n",
                        "Fitting model on combined data of shape: (2445, 41)\n",
                        "Fitting model on combined data of shape: (4000, 41)\n",
                        "Fitting model on combined data of shape: (2350, 41)\n",
                        "Fitting model on combined data of shape: (1451, 41)\n",
                        "Fitting model on combined data of shape: (1476, 41)\n",
                        "Fitting model on combined data of shape: (2194, 41)\n",
                        "Fitting model on combined data of shape: (2593, 41)\n",
                        "Fitting model on combined data of shape: (2876, 41)\n",
                        "Fitting model on combined data of shape: (1519, 41)\n",
                        "Fitting model on combined data of shape: (1248, 41)\n",
                        "Fitting model on combined data of shape: (3986, 41)\n",
                        "Fitting model on combined data of shape: (2778, 41)\n",
                        "Fitting model on combined data of shape: (3315, 41)\n",
                        "Lifelong Learning Metrics:\n",
                        "  ContinualAverage: 0.8790035831748073\n",
                        "  BackwardTransfer: -0.004411063850290314\n",
                        "  ForwardTransfer: 0.3101817454652008\n",
                        "  Time taken: 16.55 seconds\n",
                        "Fitting model with 352 samples\n",
                        "Fitting model with 2583 samples\n",
                        "Fitting model with 3371 samples\n",
                        "Fitting model with 3704 samples\n",
                        "Fitting model with 2830 samples\n",
                        "Fitting model with 2724 samples\n",
                        "Fitting model with 3581 samples\n",
                        "Fitting model with 3451 samples\n",
                        "Fitting model with 4007 samples\n",
                        "Fitting model with 3351 samples\n",
                        "Fitting model with 2453 samples\n",
                        "Fitting model with 2490 samples\n",
                        "Fitting model with 3200 samples\n",
                        "Fitting model with 3607 samples\n",
                        "Fitting model with 3892 samples\n",
                        "Fitting model with 2529 samples\n",
                        "Fitting model with 2262 samples\n",
                        "Fitting model with 4016 samples\n",
                        "Fitting model with 3802 samples\n",
                        "Fitting model with 4000 samples\n",
                        "Lifelong Learning Metrics:\n",
                        "  ContinualAverage: 0.905509964950931\n",
                        "  BackwardTransfer: -0.0021896102729045295\n",
                        "  ForwardTransfer: 0.3362580410586293\n",
                        "  Time taken: 21.94 seconds\n",
                        "--------------------\n",
                        "Running experiments for nsl-kdd - clustered_with_closest_assignment\n",
                        "Fitting model on combined data of shape: (352, 41)\n",
                        "Fitting model on combined data of shape: (2231, 41)\n",
                        "Fitting model on combined data of shape: (3852, 41)\n",
                        "Fitting model on combined data of shape: (3999, 41)\n",
                        "Fitting model on combined data of shape: (1926, 41)\n"
                    ]
                },
                {
                    "ename": "KeyboardInterrupt",
                    "evalue": "",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
                        "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
                        "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 46\u001b[39m\n\u001b[32m     43\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFinished experiments for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     44\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m40\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m \u001b[43mrun_experiments\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mAll experiments finished.\u001b[39m\u001b[33m\"\u001b[39m)\n",
                        "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 35\u001b[39m, in \u001b[36mrun_experiments\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     26\u001b[39m callbacks = [\n\u001b[32m     27\u001b[39m     ConceptMetricCallback(\n\u001b[32m     28\u001b[39m         base_metric=RocAuc(),\n\u001b[32m   (...)\u001b[39m\u001b[32m     32\u001b[39m     MemoryUsageCallback(),\n\u001b[32m     33\u001b[39m ]\n\u001b[32m     34\u001b[39m scenario = ConceptAwareScenario(dataset, strategy=strategy, callbacks=callbacks)\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m \u001b[43mscenario\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     37\u001b[39m callbacks[\u001b[32m0\u001b[39m].print_continual_average()\n\u001b[32m     38\u001b[39m end_time = time.time()\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/code/pyCLAD/experiments/../src/pyclad/scenarios/concept_aware.py:39\u001b[39m, in \u001b[36mConceptAwareScenario.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     37\u001b[39m     logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mStarting evaluation of concept \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_concept.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     38\u001b[39m     callback_composite.before_evaluation()\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m     y_predicted, anomaly_scores = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_strategy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest_concept\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconcept_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest_concept\u001b[49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     42\u001b[39m     callback_composite.after_evaluation(\n\u001b[32m     43\u001b[39m         evaluated_concept=test_concept,\n\u001b[32m     44\u001b[39m         y_true=test_concept.labels,\n\u001b[32m     45\u001b[39m         y_pred=y_predicted,\n\u001b[32m     46\u001b[39m         anomaly_scores=anomaly_scores,\n\u001b[32m     47\u001b[39m     )\n\u001b[32m     49\u001b[39m callback_composite.after_concept_processing(concept=train_concept)\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/code/pyCLAD/experiments/../src/pyclad/strategies/replay/replay.py:51\u001b[39m, in \u001b[36mReplayEnhancedStrategy.predict\u001b[39m\u001b[34m(self, data, **kwargs)\u001b[39m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, data: np.ndarray, **kwargs) -> (np.ndarray, np.ndarray):\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/code/pyCLAD/experiments/../src/pyclad/models/lof.py:37\u001b[39m, in \u001b[36mLOFModel.predict\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, data: np.ndarray) -> (np.ndarray, np.ndarray):\n\u001b[32m     36\u001b[39m     \u001b[38;5;66;03m# predict labels and anomaly scores\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m     labels = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     38\u001b[39m     scores = -\u001b[38;5;28mself\u001b[39m._model.score_samples(data)\n\u001b[32m     39\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m labels, scores\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/code/pyCLAD/experiments/../src/pyclad/models/lof.py:396\u001b[39m, in \u001b[36mLocalOutlierFactor.predict\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    375\u001b[39m \u001b[38;5;129m@available_if\u001b[39m(_check_novelty_predict)\n\u001b[32m    376\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    377\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Predict the labels (1 inlier, -1 outlier) of X according to LOF.\u001b[39;00m\n\u001b[32m    378\u001b[39m \n\u001b[32m    379\u001b[39m \u001b[33;03m    **Only available for novelty detection (when novelty is set to True).**\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    394\u001b[39m \u001b[33;03m        Returns -1 for anomalies/outliers and +1 for inliers.\u001b[39;00m\n\u001b[32m    395\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m396\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/code/pyCLAD/experiments/../src/pyclad/models/lof.py:418\u001b[39m, in \u001b[36mLocalOutlierFactor._predict\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    415\u001b[39m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m    417\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m418\u001b[39m     shifted_opposite_lof_scores = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdecision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    419\u001b[39m     is_inlier = np.ones(shifted_opposite_lof_scores.shape[\u001b[32m0\u001b[39m], dtype=\u001b[38;5;28mint\u001b[39m)\n\u001b[32m    420\u001b[39m     is_inlier[shifted_opposite_lof_scores < \u001b[32m0\u001b[39m] = -\u001b[32m1\u001b[39m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/code/pyCLAD/experiments/../src/pyclad/models/lof.py:466\u001b[39m, in \u001b[36mLocalOutlierFactor.decision_function\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    440\u001b[39m \u001b[38;5;129m@available_if\u001b[39m(_check_novelty_decision_function)\n\u001b[32m    441\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecision_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[32m    442\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Shifted opposite of the Local Outlier Factor of X.\u001b[39;00m\n\u001b[32m    443\u001b[39m \n\u001b[32m    444\u001b[39m \u001b[33;03m    Bigger is better, i.e. large values correspond to inliers.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    464\u001b[39m \u001b[33;03m        outliers, positive scores represent inliers.\u001b[39;00m\n\u001b[32m    465\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m466\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mscore_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m - \u001b[38;5;28mself\u001b[39m.offset_\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/code/pyCLAD/experiments/../src/pyclad/models/lof.py:511\u001b[39m, in \u001b[36mLocalOutlierFactor.score_samples\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    508\u001b[39m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m    509\u001b[39m X = check_array(X, accept_sparse=\u001b[33m\"\u001b[39m\u001b[33mcsr\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m511\u001b[39m distances_X, neighbors_indices_X = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkneighbors\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    512\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_neighbors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_neighbors_\u001b[49m\n\u001b[32m    513\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    515\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m X.dtype == np.float32:\n\u001b[32m    516\u001b[39m     distances_X = distances_X.astype(X.dtype, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/code/pyCLAD/.venv/lib/python3.13/site-packages/sklearn/neighbors/_base.py:869\u001b[39m, in \u001b[36mKNeighborsMixin.kneighbors\u001b[39m\u001b[34m(self, X, n_neighbors, return_distance)\u001b[39m\n\u001b[32m    862\u001b[39m use_pairwise_distances_reductions = (\n\u001b[32m    863\u001b[39m     \u001b[38;5;28mself\u001b[39m._fit_method == \u001b[33m\"\u001b[39m\u001b[33mbrute\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    864\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m ArgKmin.is_usable_for(\n\u001b[32m    865\u001b[39m         X \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fit_X, \u001b[38;5;28mself\u001b[39m._fit_X, \u001b[38;5;28mself\u001b[39m.effective_metric_\n\u001b[32m    866\u001b[39m     )\n\u001b[32m    867\u001b[39m )\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m use_pairwise_distances_reductions:\n\u001b[32m--> \u001b[39m\u001b[32m869\u001b[39m     results = \u001b[43mArgKmin\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    870\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    871\u001b[39m \u001b[43m        \u001b[49m\u001b[43mY\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit_X\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    872\u001b[39m \u001b[43m        \u001b[49m\u001b[43mk\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_neighbors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    873\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43meffective_metric_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmetric_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43meffective_metric_params_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstrategy\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mauto\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_distance\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_distance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[32m    880\u001b[39m     \u001b[38;5;28mself\u001b[39m._fit_method == \u001b[33m\"\u001b[39m\u001b[33mbrute\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.metric == \u001b[33m\"\u001b[39m\u001b[33mprecomputed\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m issparse(X)\n\u001b[32m    881\u001b[39m ):\n\u001b[32m    882\u001b[39m     results = _kneighbors_from_graph(\n\u001b[32m    883\u001b[39m         X, n_neighbors=n_neighbors, return_distance=return_distance\n\u001b[32m    884\u001b[39m     )\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/code/pyCLAD/.venv/lib/python3.13/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py:281\u001b[39m, in \u001b[36mArgKmin.compute\u001b[39m\u001b[34m(cls, X, Y, k, metric, chunk_size, metric_kwargs, strategy, return_distance)\u001b[39m\n\u001b[32m    200\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Compute the argkmin reduction.\u001b[39;00m\n\u001b[32m    201\u001b[39m \n\u001b[32m    202\u001b[39m \u001b[33;03mParameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    278\u001b[39m \u001b[33;03mreturns.\u001b[39;00m\n\u001b[32m    279\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    280\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m X.dtype == Y.dtype == np.float64:\n\u001b[32m--> \u001b[39m\u001b[32m281\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mArgKmin64\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    282\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    283\u001b[39m \u001b[43m        \u001b[49m\u001b[43mY\u001b[49m\u001b[43m=\u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    284\u001b[39m \u001b[43m        \u001b[49m\u001b[43mk\u001b[49m\u001b[43m=\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    285\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    286\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    287\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmetric_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetric_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    288\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstrategy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstrategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    289\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_distance\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_distance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    290\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    292\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m X.dtype == Y.dtype == np.float32:\n\u001b[32m    293\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ArgKmin32.compute(\n\u001b[32m    294\u001b[39m         X=X,\n\u001b[32m    295\u001b[39m         Y=Y,\n\u001b[32m   (...)\u001b[39m\u001b[32m    301\u001b[39m         return_distance=return_distance,\n\u001b[32m    302\u001b[39m     )\n",
                        "\u001b[36mFile \u001b[39m\u001b[32msklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx:59\u001b[39m, in \u001b[36msklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute\u001b[39m\u001b[34m()\u001b[39m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/code/pyCLAD/.venv/lib/python3.13/site-packages/threadpoolctl.py:592\u001b[39m, in \u001b[36m_ThreadpoolLimiter.__exit__\u001b[39m\u001b[34m(self, type, value, traceback)\u001b[39m\n\u001b[32m    589\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__enter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    590\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m592\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mtype\u001b[39m, value, traceback):\n\u001b[32m    593\u001b[39m     \u001b[38;5;28mself\u001b[39m.restore_original_limits()\n\u001b[32m    595\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m    596\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrap\u001b[39m(\u001b[38;5;28mcls\u001b[39m, controller, *, limits=\u001b[38;5;28;01mNone\u001b[39;00m, user_api=\u001b[38;5;28;01mNone\u001b[39;00m):\n",
                        "\u001b[31mKeyboardInterrupt\u001b[39m: "
                    ]
                }
            ],
            "source": [
                "import time\n",
                "\n",
                "\n",
                "def run_experiments():\n",
                "    for dataset_name, dataset_class in DATASETS.items():\n",
                "        for dataset_type in DATASET_TYPES:\n",
                "            print(f\"Running experiments for {dataset_name} - {dataset_type}\")\n",
                "            try:\n",
                "                dataset = dataset_class(dataset_type=dataset_type)\n",
                "            except Exception as e:\n",
                "                print(f\"Could not load dataset {dataset_name} with type {dataset_type}. Error: {e}\")\n",
                "                continue\n",
                "\n",
                "            for strategy_name, strategy_builder in STRATEGIES.items():\n",
                "                max_count = dataset.get_max_count()\n",
                "                # peak memory usage \n",
                "                peak_size = max_count + max_buffer_size\n",
                "                if strategy_name == \"candi\":\n",
                "                    strategy_builder = lambda model: CandiStrategy(\n",
                "                        model, max_buffer_size=peak_size//2, threshold_ratio=0.5, warmup_period=2, resize_new_regime=True\n",
                "                    )\n",
                "                start_time = time.time()\n",
                "                model = LocalOutlierFactorAdapter()\n",
                "                strategy = strategy_builder(model)\n",
                "\n",
                "                callbacks = [\n",
                "                    ConceptMetricCallback(\n",
                "                        base_metric=RocAuc(),\n",
                "                        metrics=[ContinualAverage(), BackwardTransfer(), ForwardTransfer()]\n",
                "                    ),\n",
                "                    TimeEvaluationCallback(),\n",
                "                    MemoryUsageCallback(),\n",
                "                ]\n",
                "                scenario = ConceptAwareScenario(dataset, strategy=strategy, callbacks=callbacks)\n",
                "                scenario.run()\n",
                "\n",
                "                callbacks[0].print_continual_average()\n",
                "                end_time = time.time()\n",
                "                print(f\"  Time taken: {end_time - start_time:.2f} seconds\")\n",
                "\n",
                "            print(\"-\" * 20)\n",
                "            \n",
                "        print(f\"Finished experiments for {dataset_name}.\")\n",
                "        print(\"=\" * 40)\n",
                "\n",
                "run_experiments()\n",
                "print(\"All experiments finished.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "e3969e3e",
            "metadata": {},
            "outputs": [],
            "source": [
                "# remove temporary json files\n",
                "\n",
                "import glob\n",
                "import os\n",
                "\n",
                "files = glob.glob(\"*.json\")\n",
                "for f in files:\n",
                "    os.remove(f)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.6"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
