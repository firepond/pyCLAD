{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1af66810d6fe7c75",
   "metadata": {},
   "source": [
    "# Getting Started with the `pyCLAD` library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc3644ec57ef1d23",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T12:00:12.625574Z",
     "start_time": "2025-06-19T12:00:12.622044Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyclad'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpyclad\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pyclad'"
     ]
    }
   ],
   "source": [
    "import pyclad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09f884f33bae500",
   "metadata": {},
   "source": [
    "# Example usage\n",
    "In this example, we will show how to use the `pyCLAD` library with a simple synthetic dataset to demonstrate the functionality of the library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66232291a0d8f10",
   "metadata": {},
   "source": [
    "## Dataset creation\n",
    "We start with creating a synthetic dataset with three concepts, each having training and testing data. The `Concept` class is used to represent each concept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5acc71ad1a9e89",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T12:00:12.879088Z",
     "start_time": "2025-06-19T12:00:12.671536Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pyclad.data.concept import Concept\n",
    "\n",
    "concept1_train = Concept(\"concept1\", data=np.random.rand(100, 10))\n",
    "concept1_test = Concept(\"concept1\", data=np.random.rand(100, 10), labels=np.random.randint(0, 2, 100))\n",
    "\n",
    "concept2_train = Concept(\"concept2\", data=np.random.rand(100, 10))\n",
    "concept2_test = Concept(\"concept2\", data=np.random.rand(100, 10), labels=np.random.randint(0, 2, 100))\n",
    "\n",
    "concept3_train = Concept(\"concept3\", data=np.random.rand(100, 10))\n",
    "concept3_test = Concept(\"concept3\", data=np.random.rand(100, 10), labels=np.random.randint(0, 2, 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a8e81525830ed8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T12:00:12.919573Z",
     "start_time": "2025-06-19T12:00:12.914720Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyclad.data.datasets.concepts_dataset import ConceptsDataset\n",
    "\n",
    "dataset = ConceptsDataset(\n",
    "    name=\"GeneratedDataset\",\n",
    "    train_concepts=[concept1_train, concept2_train, concept3_train],\n",
    "    test_concepts=[concept1_test, concept2_test, concept3_test],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e001c0c1325eb8a",
   "metadata": {},
   "source": [
    "## Model\n",
    "The next step is to define a model that will be used for anomaly detection. In this example, we will use the `OneClassSVM` model from the `pyod` library, which is adapted to work with the `pyCLAD` library. `pyCLAD` provides adapters for various models, allowing you to use them seamlessly within the library's framework. It is also possile to implement your own model if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69e01a13b86d65d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T12:00:14.780637Z",
     "start_time": "2025-06-19T12:00:13.033066Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyclad.models.adapters.pyod_adapters import OneClassSVMAdapter\n",
    "\n",
    "model = OneClassSVMAdapter()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26fe5b6e5907365",
   "metadata": {},
   "source": [
    "## Strategy\n",
    "\n",
    "The next step is defining a continual learning strategy that is responsible for managing the learning process across different concepts and ensuring that the model can adapt to new data without forgetting previous knowledge. In this example, we will use a simple cumulative strategy, which trains the model on all available data from previous concepts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba0c880d40497c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T12:00:14.826298Z",
     "start_time": "2025-06-19T12:00:14.821961Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyclad.strategies.baselines.cumulative import CumulativeStrategy\n",
    "\n",
    "strategy = CumulativeStrategy(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49dd1535079dcfa5",
   "metadata": {},
   "source": [
    "## Callbacks definition\n",
    "\n",
    "`pyCLAD` follows a callback-based architecture, allowing you to monitor and evaluate the model's performance during training and testing. You can define custom callbacks or use built-in ones to track metrics, log information, and visualize results. In this example, we will use the `RocAuc` metric to evaluate the model's performance on each concept. We also define `TimeEvaluationCallback` to measure the execution time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142bc5c25e13a801",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T12:00:14.877375Z",
     "start_time": "2025-06-19T12:00:14.870221Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyclad.metrics.continual.backward_transfer import BackwardTransfer\n",
    "from pyclad.metrics.continual.average_continual import ContinualAverage\n",
    "from pyclad.metrics.base.roc_auc import RocAuc\n",
    "from pyclad.metrics.continual.forward_transfer import ForwardTransfer\n",
    "from pyclad.callbacks.evaluation.concept_metric_evaluation import ConceptMetricCallback\n",
    "from pyclad.callbacks.evaluation.time_evaluation import TimeEvaluationCallback\n",
    "\n",
    "time_callback = TimeEvaluationCallback()\n",
    "metric_callback = ConceptMetricCallback(\n",
    "    base_metric=RocAuc(), metrics=[ContinualAverage(), BackwardTransfer(), ForwardTransfer()]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1955308a0e7894b",
   "metadata": {},
   "source": [
    "## Scenario creation & execution\n",
    "\n",
    "The scenario class is responsible for orchestrating the entire process, including dataset loading, model training, and evaluation. You can create a scenario by providing the dataset, strategy, and callbacks. The scenario handles the execution process that depends on the selected scenario type. In this example, we will use the `ConceptAgnosticScenario`, which means that the model is not aware of the concept boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c100c97652ce0c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T12:00:14.988410Z",
     "start_time": "2025-06-19T12:00:14.953332Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyclad.scenarios.concept_agnostic import ConceptAgnosticScenario\n",
    "\n",
    "scenario = ConceptAgnosticScenario(dataset=dataset, strategy=strategy, callbacks=[metric_callback, time_callback])\n",
    "scenario.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59be85629979734",
   "metadata": {},
   "source": [
    "## See the results from callbacks\n",
    "We can inspect the results of the callbacks to see how the model performed on each concept and how the metrics evolved over time. All callbacks provide an `info()` method that prints the results in a dict-like format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c11d973fdf6d60",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T12:00:15.041042Z",
     "start_time": "2025-06-19T12:00:15.033103Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'concept_metric_callback_ROC-AUC': {'base_metric_name': 'ROC-AUC',\n",
       "  'metrics': {'ContinualAverage': np.float64(0.48260726512827357),\n",
       "   'BackwardTransfer': np.float64(-0.001481481481481417),\n",
       "   'ForwardTransfer': np.float64(0.49327286470143616)},\n",
       "  'concepts_order': ['concept1', 'concept2', 'concept3'],\n",
       "  'metric_matrix': defaultdict(dict,\n",
       "              {'concept1': {'concept1': 0.5268686868686868,\n",
       "                'concept2': 0.3777777777777778,\n",
       "                'concept3': 0.5474189675870349},\n",
       "               'concept2': {'concept1': 0.5252525252525253,\n",
       "                'concept2': 0.38383838383838376,\n",
       "                'concept3': 0.5546218487394958},\n",
       "               'concept3': {'concept1': 0.5216161616161616,\n",
       "                'concept2': 0.3846464646464647,\n",
       "                'concept3': 0.5534213685474189}})}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_callback.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856b1d6c636cac27",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T12:00:15.120927Z",
     "start_time": "2025-06-19T12:00:15.116379Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'time_evaluation_callback': {'time_by_concept': defaultdict(<function pyclad.callbacks.evaluation.time_evaluation.TimeEvaluationCallback.__init__.<locals>.<lambda>()>,\n",
       "              {'concept1': {'train_time': 0.0013430118560791016,\n",
       "                'eval_time': 0.003213167190551758},\n",
       "               'concept2': {'train_time': 0.0010581016540527344,\n",
       "                'eval_time': 0.0028150081634521484},\n",
       "               'concept3': {'train_time': 0.0019419193267822266,\n",
       "                'eval_time': 0.0026607513427734375}}),\n",
       "  'train_time_total': 0.0043430328369140625,\n",
       "  'eval_time_total': 0.008688926696777344}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_callback.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73042e8fdd095a15",
   "metadata": {},
   "source": [
    "## Write results to file\n",
    "We can leverage the `JsonOutputWriter` to save the results of the scenario execution saved in the callbacks, as well as an additional information about the model, dataset, and strategy. This allows for easy sharing and reproducibility of the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c11f6d66c27cb1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T12:00:26.571206Z",
     "start_time": "2025-06-19T12:00:26.562761Z"
    }
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "from pyclad.output.json_writer import JsonOutputWriter\n",
    "\n",
    "# Save the results\n",
    "output_writer = JsonOutputWriter(pathlib.Path(\"output.json\"))\n",
    "output_writer.write([model, dataset, strategy, metric_callback, time_callback])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b56230c2a7aeb4e",
   "metadata": {},
   "source": [
    "# UNSW Dataset Example\n",
    "We can also leverage real-world datasets to test the functionality of the `pyCLAD` library. In this example, we will use the UNSW dataset, which is a well-known dataset for anomaly detection tasks. The dataset is adapted to continual anomaly detection. `pyCLAD` provides a few datasets out of the box, including the UNSW dataset. You can find more datasets in the `pyclad.data.datasets` module. It is also possible to implement your own dataset by following the structure of the existing datasets (see [docs](https://pyclad.readthedocs.io/en/latest/) for more details)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61aaabe727fb4e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/firepond/code/pyCLAD/clad_venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "INFO:pyclad.scenarios.concept_aware:Starting training on concept Cluster_0\n",
      "Training: 100%|██████████| 20/20 [00:17<00:00,  1.14it/s]\n",
      "INFO:pyclad.scenarios.concept_aware:Starting evaluation of concept Cluster_0\n",
      "INFO:pyclad.scenarios.concept_aware:Starting evaluation of concept Cluster_1\n",
      "INFO:pyclad.scenarios.concept_aware:Starting evaluation of concept Cluster_2\n",
      "INFO:pyclad.scenarios.concept_aware:Starting evaluation of concept Cluster_3\n",
      "INFO:pyclad.scenarios.concept_aware:Starting evaluation of concept Cluster_4\n",
      "INFO:pyclad.scenarios.concept_aware:Starting evaluation of concept Cluster_5\n",
      "INFO:pyclad.scenarios.concept_aware:Starting evaluation of concept Cluster_6\n",
      "INFO:pyclad.scenarios.concept_aware:Starting evaluation of concept Cluster_7\n",
      "INFO:pyclad.scenarios.concept_aware:Starting evaluation of concept Cluster_8\n",
      "INFO:pyclad.scenarios.concept_aware:Starting evaluation of concept Cluster_9\n",
      "INFO:pyclad.scenarios.concept_aware:Starting training on concept Cluster_1\n",
      "Training: 100%|██████████| 20/20 [00:10<00:00,  1.88it/s]\n",
      "INFO:pyclad.scenarios.concept_aware:Starting evaluation of concept Cluster_0\n",
      "INFO:pyclad.scenarios.concept_aware:Starting evaluation of concept Cluster_1\n",
      "INFO:pyclad.scenarios.concept_aware:Starting evaluation of concept Cluster_2\n",
      "INFO:pyclad.scenarios.concept_aware:Starting evaluation of concept Cluster_3\n",
      "INFO:pyclad.scenarios.concept_aware:Starting evaluation of concept Cluster_4\n",
      "INFO:pyclad.scenarios.concept_aware:Starting evaluation of concept Cluster_5\n",
      "INFO:pyclad.scenarios.concept_aware:Starting evaluation of concept Cluster_6\n",
      "INFO:pyclad.scenarios.concept_aware:Starting evaluation of concept Cluster_7\n",
      "INFO:pyclad.scenarios.concept_aware:Starting evaluation of concept Cluster_8\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 51\u001b[39m\n\u001b[32m     42\u001b[39m callbacks = [\n\u001b[32m     43\u001b[39m     ConceptMetricCallback(\n\u001b[32m     44\u001b[39m         base_metric=RocAuc(),\n\u001b[32m   (...)\u001b[39m\u001b[32m     48\u001b[39m     MemoryUsageCallback(),\n\u001b[32m     49\u001b[39m ]\n\u001b[32m     50\u001b[39m scenario = ConceptAwareScenario(dataset, strategy=strategy, callbacks=callbacks)\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m \u001b[43mscenario\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     53\u001b[39m output_writer = JsonOutputWriter(pathlib.Path(\u001b[33m\"\u001b[39m\u001b[33moutput-unsw.json\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m     54\u001b[39m output_writer.write([model, dataset, strategy, *callbacks])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/pyCLAD/clad_venv/lib/python3.13/site-packages/pyclad/scenarios/concept_aware.py:34\u001b[39m, in \u001b[36mrun\u001b[39m\u001b[34m(self)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/pyCLAD/clad_venv/lib/python3.13/site-packages/pyclad/strategies/replay/replay.py:43\u001b[39m, in \u001b[36mpredict\u001b[39m\u001b[34m(self, data, **kwargs)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/pyCLAD/clad_venv/lib/python3.13/site-packages/pyclad/models/adapters/pyod_adapters.py:21\u001b[39m, in \u001b[36mpredict\u001b[39m\u001b[34m(self, data)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/pyCLAD/clad_venv/lib/python3.13/site-packages/pyod/models/base_dl.py:290\u001b[39m, in \u001b[36mBaseDeepLearningDetector.decision_function\u001b[39m\u001b[34m(self, X, batch_size)\u001b[39m\n\u001b[32m    284\u001b[39m data_loader = torch.utils.data.DataLoader(\n\u001b[32m    285\u001b[39m     dataset=dataset,\n\u001b[32m    286\u001b[39m     batch_size=\u001b[38;5;28mself\u001b[39m.batch_size \u001b[38;5;28;01mif\u001b[39;00m batch_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m batch_size,\n\u001b[32m    287\u001b[39m     shuffle=\u001b[38;5;28;01mFalse\u001b[39;00m, drop_last=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    289\u001b[39m \u001b[38;5;66;03m# evaluate the model\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m290\u001b[39m anomaly_scores = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    291\u001b[39m anomaly_scores = \u001b[38;5;28mself\u001b[39m.decision_function_update(anomaly_scores)\n\u001b[32m    292\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m anomaly_scores\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/pyCLAD/clad_venv/lib/python3.13/site-packages/pyod/models/base_dl.py:315\u001b[39m, in \u001b[36mBaseDeepLearningDetector.evaluate\u001b[39m\u001b[34m(self, data_loader)\u001b[39m\n\u001b[32m    313\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m    314\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m batch_data \u001b[38;5;129;01min\u001b[39;00m data_loader:\n\u001b[32m--> \u001b[39m\u001b[32m315\u001b[39m         score = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mevaluating_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    316\u001b[39m         anamoly_scores.append(score)\n\u001b[32m    317\u001b[39m anamoly_scores = np.concatenate(anamoly_scores)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/pyCLAD/clad_venv/lib/python3.13/site-packages/pyod/models/vae.py:263\u001b[39m, in \u001b[36mVAE.evaluating_forward\u001b[39m\u001b[34m(self, batch_data)\u001b[39m\n\u001b[32m    261\u001b[39m x = batch_data\n\u001b[32m    262\u001b[39m x_gpu = x.to(\u001b[38;5;28mself\u001b[39m.device)\n\u001b[32m--> \u001b[39m\u001b[32m263\u001b[39m x_recon, _, _ = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_gpu\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    264\u001b[39m score = pairwise_distances_no_broadcast(x.numpy(),\n\u001b[32m    265\u001b[39m                                         x_recon.cpu().numpy())\n\u001b[32m    266\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m score\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/pyCLAD/clad_venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/pyCLAD/clad_venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/pyCLAD/clad_venv/lib/python3.13/site-packages/pyod/models/vae.py:322\u001b[39m, in \u001b[36mVAEModel.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    321\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m--> \u001b[39m\u001b[32m322\u001b[39m     z_mu, z_logvar = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    323\u001b[39m     z = \u001b[38;5;28mself\u001b[39m.reparameterize(z_mu, z_logvar)\n\u001b[32m    324\u001b[39m     x_recon = \u001b[38;5;28mself\u001b[39m.decode(z)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/pyCLAD/clad_venv/lib/python3.13/site-packages/pyod/models/vae.py:335\u001b[39m, in \u001b[36mVAEModel.encode\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    333\u001b[39m h = \u001b[38;5;28mself\u001b[39m.encoder(x)\n\u001b[32m    334\u001b[39m z_mu = \u001b[38;5;28mself\u001b[39m.encoder_mu(h)\n\u001b[32m--> \u001b[39m\u001b[32m335\u001b[39m z_logvar = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoder_logvar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    336\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m z_mu, z_logvar\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/pyCLAD/clad_venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/pyCLAD/clad_venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/pyCLAD/clad_venv/lib/python3.13/site-packages/torch/nn/modules/linear.py:125\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import pathlib\n",
    "\n",
    "from pyod.models.vae import VAE\n",
    "\n",
    "from pyclad.callbacks.evaluation.concept_metric_evaluation import ConceptMetricCallback\n",
    "from pyclad.callbacks.evaluation.memory_usage import MemoryUsageCallback\n",
    "from pyclad.callbacks.evaluation.time_evaluation import TimeEvaluationCallback\n",
    "from pyclad.data.datasets.unsw_dataset import UnswDataset\n",
    "from pyclad.metrics.base.roc_auc import RocAuc\n",
    "from pyclad.metrics.continual.average_continual import ContinualAverage\n",
    "from pyclad.metrics.continual.backward_transfer import BackwardTransfer\n",
    "from pyclad.metrics.continual.forward_transfer import ForwardTransfer\n",
    "from pyclad.models.adapters.pyod_adapters import PyODAdapter\n",
    "from pyclad.output.json_writer import JsonOutputWriter\n",
    "from pyclad.scenarios.concept_aware import ConceptAwareScenario\n",
    "from pyclad.strategies.replay.buffers.adaptive_balanced import (\n",
    "    AdaptiveBalancedReplayBuffer,\n",
    ")\n",
    "from pyclad.strategies.replay.replay import ReplayEnhancedStrategy\n",
    "from pyclad.strategies.replay.selection.random import RandomSelection\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, handlers=[logging.FileHandler(\"debug.log\"), logging.StreamHandler()])\n",
    "\n",
    "\"\"\"\n",
    "This example showcase how to run a concept aware scenario using the UNSW dataset adopted to continual anomaly\n",
    "detection using the method proposed here <https://github.com/lifelonglab/lifelong-anomaly-detection-scenarios>\n",
    "\"\"\"\n",
    "dataset = UnswDataset(dataset_type=\"random_anomalies\")\n",
    "model = PyODAdapter(\n",
    "    VAE(\n",
    "        encoder_neuron_list=[32, 24, 16],\n",
    "        decoder_neuron_list=[16, 24, 32],\n",
    "        latent_dim=8,\n",
    "        epoch_num=20,\n",
    "        preprocessing=False,\n",
    "    ),\n",
    "    model_name=\"VAE\",\n",
    ")\n",
    "replay_buffer = AdaptiveBalancedReplayBuffer(selection_method=RandomSelection(), max_size=1000)\n",
    "strategy = ReplayEnhancedStrategy(model, replay_buffer)\n",
    "callbacks = [\n",
    "    ConceptMetricCallback(\n",
    "        base_metric=RocAuc(),\n",
    "        metrics=[ContinualAverage(), BackwardTransfer(), ForwardTransfer()],\n",
    "    ),\n",
    "    TimeEvaluationCallback(),\n",
    "    MemoryUsageCallback(),\n",
    "]\n",
    "scenario = ConceptAwareScenario(dataset, strategy=strategy, callbacks=callbacks)\n",
    "scenario.run()\n",
    "\n",
    "output_writer = JsonOutputWriter(pathlib.Path(\"output-unsw.json\"))\n",
    "output_writer.write([model, dataset, strategy, *callbacks])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58121a43d73a9d31",
   "metadata": {},
   "source": [
    "# Try it yourself!\n",
    "In this section, we will guide you through the process of running experiments with different datasets, models, and strategies using the `pyCLAD` library. You can follow the steps below to set up your own experiments and analyze the results. You will experiment with two strategies on the same dataset to compare their performance. This will help you understand how different strategies affect the performance of the model on the same dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62512d18558f63bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-25T07:27:52.475696Z",
     "start_time": "2025-06-25T07:27:49.591619Z"
    }
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import pathlib\n",
    "\n",
    "# Datasets\n",
    "from pyclad.data.datasets.unsw_dataset import UnswDataset\n",
    "from pyclad.data.datasets.nsl_kdd_dataset import NslKddDataset\n",
    "from pyclad.data.datasets.wind_energy_dataset import WindEnergyDataset\n",
    "from pyclad.data.datasets.energy_plants_dataset import EnergyPlantsDataset\n",
    "\n",
    "\n",
    "# Scenarios\n",
    "from pyclad.scenarios.concept_aware import ConceptAwareScenario\n",
    "\n",
    "# Models\n",
    "from pyclad.models.adapters.pyod_adapters import IsolationForestAdapter, OneClassSVMAdapter, LocalOutlierFactorAdapter, PyODAdapter\n",
    "\n",
    "# Strategies\n",
    "from pyclad.strategies.baselines.cumulative import CumulativeStrategy\n",
    "from pyclad.strategies.baselines.naive import NaiveStrategy\n",
    "from pyclad.strategies.replay.replay import ReplayEnhancedStrategy\n",
    "\n",
    "# Additional imports for replay strategies\n",
    "from pyclad.strategies.replay.buffers.adaptive_balanced import (\n",
    "    AdaptiveBalancedReplayBuffer,\n",
    ")\n",
    "from pyclad.strategies.replay.selection.random import RandomSelection\n",
    "\n",
    "\n",
    "# Callback and metrics\n",
    "from pyclad.callbacks.evaluation.concept_metric_evaluation import ConceptMetricCallback\n",
    "from pyclad.callbacks.evaluation.memory_usage import MemoryUsageCallback\n",
    "from pyclad.callbacks.evaluation.time_evaluation import TimeEvaluationCallback\n",
    "from pyclad.metrics.base.roc_auc import RocAuc\n",
    "from pyclad.metrics.continual.average_continual import ContinualAverage\n",
    "from pyclad.metrics.continual.backward_transfer import BackwardTransfer\n",
    "from pyclad.metrics.continual.forward_transfer import ForwardTransfer\n",
    "from pyclad.output.json_writer import JsonOutputWriter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd98444f7271a7d",
   "metadata": {},
   "source": [
    "Select the dataset that you want to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6fea7eac2fa8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ...  # Replace with your dataset, e.g., `UnswDataset(dataset_type=\"random_anomalies\")`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0343dea27a1cc5e",
   "metadata": {},
   "source": [
    "Select the base model that you want to use. You can choose from the available models in `pyCLAD` or implement your own model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18f1f3b7b179633",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T16:00:02.364051Z",
     "start_time": "2025-06-24T16:00:02.359625Z"
    }
   },
   "outputs": [],
   "source": [
    "model = ...  # Replace with your model, e.g., `IsolationForestAdapter()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4a5b47b455cf38",
   "metadata": {},
   "source": [
    "Select the strategy that you want to use. You can choose from the available strategies in `pyCLAD` or implement your own strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4933b9585b9dc41f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T16:00:35.400801Z",
     "start_time": "2025-06-24T16:00:35.397723Z"
    }
   },
   "outputs": [],
   "source": [
    "strategy = ...  # Replace with your strategy, e.g., `CumulativeStrategy(model)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249f3516cd57d53a",
   "metadata": {},
   "source": [
    "Let's run the experiment with the selected dataset, model, and strategy. We will also use the `ConceptMetricCallback` to evaluate the model's performance on each concept and the `TimeEvaluationCallback` to measure the execution time. The results will be saved to a JSON file (`output-strategy1.json`) using the `JsonOutputWriter`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f890bb0a0fbc8eb2",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ellipsis' object has no attribute 'train_concepts'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      2\u001b[39m callbacks = [\n\u001b[32m      3\u001b[39m     ConceptMetricCallback(\n\u001b[32m      4\u001b[39m         base_metric=RocAuc(),\n\u001b[32m   (...)\u001b[39m\u001b[32m      8\u001b[39m     MemoryUsageCallback(),\n\u001b[32m      9\u001b[39m ]\n\u001b[32m     10\u001b[39m scenario = ConceptAwareScenario(dataset, strategy=strategy, callbacks=callbacks)\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[43mscenario\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m output_writer = JsonOutputWriter(pathlib.Path(\u001b[33m\"\u001b[39m\u001b[33moutput-strategy1.json\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m     14\u001b[39m output_writer.write([model, dataset, strategy, *callbacks])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/pyCLAD/clad_venv/lib/python3.13/site-packages/pyclad/scenarios/concept_aware.py:22\u001b[39m, in \u001b[36mConceptAwareScenario.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     19\u001b[39m callback_composite = CallbackComposite(\u001b[38;5;28mself\u001b[39m._callbacks)\n\u001b[32m     20\u001b[39m callback_composite.before_scenario()\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m train_concept \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain_concepts\u001b[49m():\n\u001b[32m     23\u001b[39m     logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mStarting training on concept \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_concept.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     24\u001b[39m     callback_composite.before_concept_processing(concept=train_concept)\n",
      "\u001b[31mAttributeError\u001b[39m: 'ellipsis' object has no attribute 'train_concepts'"
     ]
    }
   ],
   "source": [
    "# Run the experiment\n",
    "callbacks = [\n",
    "    ConceptMetricCallback(\n",
    "        base_metric=RocAuc(),\n",
    "        metrics=[ContinualAverage(), BackwardTransfer(), ForwardTransfer()],\n",
    "    ),\n",
    "    TimeEvaluationCallback(),\n",
    "    MemoryUsageCallback(),\n",
    "]\n",
    "scenario = ConceptAwareScenario(dataset, strategy=strategy, callbacks=callbacks)\n",
    "scenario.run()\n",
    "\n",
    "output_writer = JsonOutputWriter(pathlib.Path(\"output-strategy1.json\"))\n",
    "output_writer.write([model, dataset, strategy, *callbacks])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206304a1299409ef",
   "metadata": {},
   "source": [
    "Let's recreate the model and select another strategy to compare the results with the previous experiment. This will help you understand how different strategies affect the performance of the model on the same dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59e121361d2e196",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ... # Use the same model as before"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2235c93648ce43",
   "metadata": {},
   "source": [
    "Select a different strategy to compare the results with the previous experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1f352c55cca620",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-25T07:21:30.477134Z",
     "start_time": "2025-06-25T07:21:30.470569Z"
    }
   },
   "outputs": [],
   "source": [
    "strategy = ...  # Replace with your strategy, e.g., `CumulativeStrategy(model)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ad6d51d7e196c9",
   "metadata": {},
   "source": [
    " Now, let's run the experiment again with the new strategy. The results will be saved in `output-strategy2.json` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17694740cc3eec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the experiment\n",
    "callbacks = [\n",
    "    ConceptMetricCallback(\n",
    "        base_metric=RocAuc(),\n",
    "        metrics=[ContinualAverage(), BackwardTransfer(), ForwardTransfer()],\n",
    "    ),\n",
    "    TimeEvaluationCallback(),\n",
    "    MemoryUsageCallback(),\n",
    "]\n",
    "scenario = ConceptAwareScenario(dataset, strategy=strategy, callbacks=callbacks)\n",
    "scenario.run()\n",
    "\n",
    "output_writer = JsonOutputWriter(pathlib.Path(\"output-strategy2.json\"))\n",
    "output_writer.write([model, dataset, strategy, *callbacks])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f22e9a78fc629d",
   "metadata": {},
   "source": [
    "You can analyze the results from both experiments by inspecting the output files (`output-strategy1.json` and `output-strategy2.json`). This will help you understand how different strategies affect the performance of the model on the same dataset. You can focus on the summarized metrics such as `ContinualAverage`, `BackwardTransfer`, and `ForwardTransfer` to compare the performance of the model across different strategies. You can find them in the `concept_metric_callback_ROC-AUC` -> `metrics` section of the output files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3512916de17a38b",
   "metadata": {},
   "source": [
    "# Extend the `pyCLAD` library :)\n",
    "You can try the `pyCLAD` library with your own datasets and models. The library is designed to be flexible and extensible, allowing you to adapt it to your specific needs. You can also contribute to the library by implementing new models, strategies, or datasets. Check out the [documentation](https://pyclad.readthedocs.io/en/latest/) for more information on how to get started."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390ea9788735416",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clad_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
