{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8658021d",
   "metadata": {},
   "source": [
    "# Comparison of Replay Strategies in pyCLAD\n",
    "\n",
    "This notebook compares the performance of `ReplayEnhancedStrategy` and `BalancedReservoirSamplingStrategy` from the `pyCLAD` library.\n",
    "The comparison is performed across four datasets: Energy, NSL-KDD, UNSW, and Wind.\n",
    "For each dataset, three different data scenarios are used: `random_anomalies`, `clustered_with_closest_assignment`, and `clustered_with_random_assignment`.\n",
    "\n",
    "The notebook is divided into three main parts:\n",
    "1.  **Setup**: Imports necessary libraries and defines the configuration for datasets, strategies, and output directories.\n",
    "2.  **Run Experiments**: Executes the experiments for each combination of dataset, scenario, and strategy, saving the results to JSON files.\n",
    "3.  **Analyze Results**: Loads the saved results, generates heatmaps for each experiment, and creates comparison heatmaps to visualize the performance difference between the two strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c359695",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/firepond/code/pyCLAD/clad_venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete.\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Datasets\n",
    "from pyclad.data.datasets.unsw_dataset import UnswDataset\n",
    "from pyclad.data.datasets.nsl_kdd_dataset import NslKddDataset\n",
    "from pyclad.data.datasets.wind_energy_dataset import WindEnergyDataset\n",
    "from pyclad.data.datasets.energy_plants_dataset import EnergyPlantsDataset\n",
    "\n",
    "# Scenarios\n",
    "from pyclad.scenarios.concept_aware import ConceptAwareScenario\n",
    "\n",
    "from pyclad.metrics.continual.average_continual import ContinualAverage\n",
    "from pyclad.metrics.continual.backward_transfer import BackwardTransfer\n",
    "from pyclad.metrics.continual.forward_transfer import ForwardTransfer\n",
    "# Models\n",
    "from pyclad.models.adapters.pyod_adapters import IsolationForestAdapter\n",
    "from pyclad.models.adapters.pyod_adapters import LocalOutlierFactorAdapter\n",
    "\n",
    "# Strategies\n",
    "from pyclad.strategies.replay.replay import ReplayEnhancedStrategy\n",
    "from pyclad.strategies.replay.reservoir import BalancedReservoirSamplingStrategy\n",
    "\n",
    "# Additional imports for replay strategies\n",
    "from pyclad.strategies.replay.buffers.adaptive_balanced import (\n",
    "    AdaptiveBalancedReplayBuffer,\n",
    ")\n",
    "from pyclad.strategies.replay.selection.random import RandomSelection\n",
    "\n",
    "# Callback and metrics\n",
    "from pyclad.callbacks.evaluation.concept_metric_evaluation import ConceptMetricCallback\n",
    "from pyclad.callbacks.evaluation.memory_usage import MemoryUsageCallback\n",
    "from pyclad.callbacks.evaluation.time_evaluation import TimeEvaluationCallback\n",
    "from pyclad.metrics.base.roc_auc import RocAuc\n",
    "from pyclad.output.json_writer import JsonOutputWriter\n",
    "\n",
    "# Configuration\n",
    "DATASETS = {\n",
    "    \"energy\": EnergyPlantsDataset,\n",
    "    \"nsl-kdd\": NslKddDataset,\n",
    "    \"unsw\": UnswDataset,\n",
    "    \"wind\": WindEnergyDataset,\n",
    "}\n",
    "\n",
    "DATASET_TYPES = [\n",
    "    \"random_anomalies\",\n",
    "    \"clustered_with_closest_assignment\",\n",
    "    \"clustered_with_random_assignment\",\n",
    "]\n",
    "\n",
    "STRATEGIES = {\n",
    "    \"replay_enhanced\": lambda model: ReplayEnhancedStrategy(\n",
    "        model,\n",
    "        AdaptiveBalancedReplayBuffer(selection_method=RandomSelection(), max_size=3000),\n",
    "    ),\n",
    "    \"balanced_reservoir\": lambda model: BalancedReservoirSamplingStrategy(\n",
    "        model, max_buffer_size=3000\n",
    "    ),\n",
    "}\n",
    "\n",
    "RESULTS_DIR = pathlib.Path(\"comparison_results\")\n",
    "PLOTS_DIR = pathlib.Path(\"comparison_plots\")\n",
    "RESULTS_DIR.mkdir(exist_ok=True)\n",
    "PLOTS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"Setup complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f42f85d",
   "metadata": {},
   "source": [
    "### Run Experiments\n",
    "\n",
    "The following cell runs the experiments. It iterates through each dataset and dataset type, and for each, it runs both the `ReplayEnhancedStrategy` and the `BalancedReservoirSamplingStrategy`. The results are saved in the `comparison_results` directory.\n",
    "\n",
    "**Note:** This process can be time-consuming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a73b19b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiments for energy - random_anomalies\n",
      "  with strategy: replay_enhanced\n",
      "    Results saved to comparison_results/energy_random_anomalies_replay_enhanced.json\n",
      "  with strategy: balanced_reservoir\n",
      "    Results saved to comparison_results/energy_random_anomalies_balanced_reservoir.json\n",
      "Running experiments for energy - clustered_with_closest_assignment\n",
      "  with strategy: replay_enhanced\n",
      "    Results saved to comparison_results/energy_clustered_with_closest_assignment_replay_enhanced.json\n",
      "  with strategy: balanced_reservoir\n",
      "    Results saved to comparison_results/energy_clustered_with_closest_assignment_balanced_reservoir.json\n",
      "Running experiments for energy - clustered_with_random_assignment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 60000 examples [00:00, 994071.87 examples/s]\n",
      "Generating test split: 45813 examples [00:00, 1214133.66 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  with strategy: replay_enhanced\n",
      "    Results saved to comparison_results/energy_clustered_with_random_assignment_replay_enhanced.json\n",
      "  with strategy: balanced_reservoir\n",
      "    Results saved to comparison_results/energy_clustered_with_random_assignment_balanced_reservoir.json\n",
      "Running experiments for nsl-kdd - random_anomalies\n",
      "  with strategy: replay_enhanced\n",
      "    Results saved to comparison_results/nsl-kdd_random_anomalies_replay_enhanced.json\n",
      "  with strategy: balanced_reservoir\n",
      "    Results saved to comparison_results/nsl-kdd_random_anomalies_balanced_reservoir.json\n",
      "Running experiments for nsl-kdd - clustered_with_closest_assignment\n",
      "  with strategy: replay_enhanced\n",
      "    Results saved to comparison_results/nsl-kdd_clustered_with_closest_assignment_replay_enhanced.json\n",
      "  with strategy: balanced_reservoir\n",
      "    Results saved to comparison_results/nsl-kdd_clustered_with_closest_assignment_balanced_reservoir.json\n",
      "Running experiments for nsl-kdd - clustered_with_random_assignment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 30780 examples [00:00, 415540.95 examples/s]\n",
      "Generating test split: 47515 examples [00:00, 475554.09 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  with strategy: replay_enhanced\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 32\u001b[39m\n\u001b[32m     29\u001b[39m                 output_writer.write([model, dataset, strategy, *callbacks])\n\u001b[32m     30\u001b[39m                 \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m    Results saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_writer._path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m \u001b[43mrun_experiments\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mAll experiments finished.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 25\u001b[39m, in \u001b[36mrun_experiments\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     16\u001b[39m callbacks = [\n\u001b[32m     17\u001b[39m     ConceptMetricCallback(\n\u001b[32m     18\u001b[39m         base_metric=RocAuc(),\n\u001b[32m   (...)\u001b[39m\u001b[32m     22\u001b[39m     MemoryUsageCallback(),\n\u001b[32m     23\u001b[39m ]\n\u001b[32m     24\u001b[39m scenario = ConceptAwareScenario(dataset, strategy=strategy, callbacks=callbacks)\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m \u001b[43mscenario\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m output_filename = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstrategy_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.json\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     28\u001b[39m output_writer = JsonOutputWriter(RESULTS_DIR / output_filename)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/pyCLAD/src/pyclad/scenarios/concept_aware.py:27\u001b[39m, in \u001b[36mConceptAwareScenario.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     24\u001b[39m callback_composite.before_concept_processing(concept=train_concept)\n\u001b[32m     25\u001b[39m callback_composite.before_training()\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_strategy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_concept\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconcept_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_concept\u001b[49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     29\u001b[39m callback_composite.after_training(learned_concept=train_concept)\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m test_concept \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._dataset.test_concepts():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/pyCLAD/src/pyclad/strategies/replay/replay.py:39\u001b[39m, in \u001b[36mReplayEnhancedStrategy.learn\u001b[39m\u001b[34m(self, data, **kwargs)\u001b[39m\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mlearn\u001b[39m(\u001b[38;5;28mself\u001b[39m, data: np.ndarray, **kwargs) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_buffer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_buffer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m>\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     40\u001b[39m     \u001b[38;5;28mself\u001b[39m._buffer.update(data)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/pyCLAD/src/pyclad/models/adapters/pyod_adapters.py:18\u001b[39m, in \u001b[36mPyODAdapter.fit\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, data: np.ndarray):\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/pyCLAD/clad_venv/lib/python3.13/site-packages/pyod/models/iforest.py:217\u001b[39m, in \u001b[36mIForest.fit\u001b[39m\u001b[34m(self, X, y)\u001b[39m\n\u001b[32m    204\u001b[39m \u001b[38;5;66;03m# In sklearn 0.20+ new behaviour is added (arg behaviour={'new','old'})\u001b[39;00m\n\u001b[32m    205\u001b[39m \u001b[38;5;66;03m# to IsolationForest that shifts the location of the anomaly scores\u001b[39;00m\n\u001b[32m    206\u001b[39m \u001b[38;5;66;03m# noinspection PyProtectedMember\u001b[39;00m\n\u001b[32m    208\u001b[39m \u001b[38;5;28mself\u001b[39m.detector_ = IsolationForest(n_estimators=\u001b[38;5;28mself\u001b[39m.n_estimators,\n\u001b[32m    209\u001b[39m                                  max_samples=\u001b[38;5;28mself\u001b[39m.max_samples,\n\u001b[32m    210\u001b[39m                                  contamination=\u001b[38;5;28mself\u001b[39m.contamination,\n\u001b[32m   (...)\u001b[39m\u001b[32m    214\u001b[39m                                  random_state=\u001b[38;5;28mself\u001b[39m.random_state,\n\u001b[32m    215\u001b[39m                                  verbose=\u001b[38;5;28mself\u001b[39m.verbose)\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdetector_\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;66;03m# invert decision_scores_. Outliers comes with higher outlier scores.\u001b[39;00m\n\u001b[32m    220\u001b[39m \u001b[38;5;28mself\u001b[39m.decision_scores_ = invert_order(\n\u001b[32m    221\u001b[39m     \u001b[38;5;28mself\u001b[39m.detector_.decision_function(X))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/pyCLAD/clad_venv/lib/python3.13/site-packages/sklearn/base.py:1363\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1356\u001b[39m     estimator._validate_params()\n\u001b[32m   1358\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1359\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1360\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1361\u001b[39m     )\n\u001b[32m   1362\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1363\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/pyCLAD/clad_venv/lib/python3.13/site-packages/sklearn/ensemble/_iforest.py:350\u001b[39m, in \u001b[36mIsolationForest.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    348\u001b[39m \u001b[38;5;28mself\u001b[39m.max_samples_ = max_samples\n\u001b[32m    349\u001b[39m max_depth = \u001b[38;5;28mint\u001b[39m(np.ceil(np.log2(\u001b[38;5;28mmax\u001b[39m(max_samples, \u001b[32m2\u001b[39m))))\n\u001b[32m--> \u001b[39m\u001b[32m350\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_depth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_depth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[38;5;28mself\u001b[39m._average_path_length_per_tree, \u001b[38;5;28mself\u001b[39m._decision_path_lengths = \u001b[38;5;28mzip\u001b[39m(\n\u001b[32m    360\u001b[39m     *[\n\u001b[32m    361\u001b[39m         (\n\u001b[32m   (...)\u001b[39m\u001b[32m    366\u001b[39m     ]\n\u001b[32m    367\u001b[39m )\n\u001b[32m    369\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.contamination == \u001b[33m\"\u001b[39m\u001b[33mauto\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    370\u001b[39m     \u001b[38;5;66;03m# 0.5 plays a special role as described in the original paper.\u001b[39;00m\n\u001b[32m    371\u001b[39m     \u001b[38;5;66;03m# we take the opposite as we consider the opposite of their score.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/pyCLAD/clad_venv/lib/python3.13/site-packages/sklearn/ensemble/_bagging.py:547\u001b[39m, in \u001b[36mBaseBagging._fit\u001b[39m\u001b[34m(self, X, y, max_samples, max_depth, check_input, sample_weight, **fit_params)\u001b[39m\n\u001b[32m    544\u001b[39m seeds = random_state.randint(MAX_INT, size=n_more_estimators)\n\u001b[32m    545\u001b[39m \u001b[38;5;28mself\u001b[39m._seeds = seeds\n\u001b[32m--> \u001b[39m\u001b[32m547\u001b[39m all_results = \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    548\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_parallel_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    549\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    550\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_estimators\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    551\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_estimators\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    552\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    553\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    554\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    555\u001b[39m \u001b[43m        \u001b[49m\u001b[43mseeds\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstarts\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstarts\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    556\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtotal_n_estimators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    557\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    558\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    559\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    560\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    561\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    562\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    564\u001b[39m \u001b[38;5;66;03m# Reduce\u001b[39;00m\n\u001b[32m    565\u001b[39m \u001b[38;5;28mself\u001b[39m.estimators_ += \u001b[38;5;28mlist\u001b[39m(\n\u001b[32m    566\u001b[39m     itertools.chain.from_iterable(t[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m all_results)\n\u001b[32m    567\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/pyCLAD/clad_venv/lib/python3.13/site-packages/sklearn/utils/parallel.py:82\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     73\u001b[39m warning_filters = warnings.filters\n\u001b[32m     74\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     75\u001b[39m     (\n\u001b[32m     76\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     81\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/pyCLAD/clad_venv/lib/python3.13/site-packages/joblib/parallel.py:1986\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1984\u001b[39m     output = \u001b[38;5;28mself\u001b[39m._get_sequential_output(iterable)\n\u001b[32m   1985\u001b[39m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m1986\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1988\u001b[39m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[32m   1989\u001b[39m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[32m   1990\u001b[39m \u001b[38;5;66;03m# reused, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[32m   1991\u001b[39m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[32m   1992\u001b[39m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[32m   1993\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/pyCLAD/clad_venv/lib/python3.13/site-packages/joblib/parallel.py:1914\u001b[39m, in \u001b[36mParallel._get_sequential_output\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1912\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_batches += \u001b[32m1\u001b[39m\n\u001b[32m   1913\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_tasks += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1914\u001b[39m res = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1915\u001b[39m \u001b[38;5;28mself\u001b[39m.n_completed_tasks += \u001b[32m1\u001b[39m\n\u001b[32m   1916\u001b[39m \u001b[38;5;28mself\u001b[39m.print_progress()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/pyCLAD/clad_venv/lib/python3.13/site-packages/sklearn/utils/parallel.py:147\u001b[39m, in \u001b[36m_FuncWrapper.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(**config), warnings.catch_warnings():\n\u001b[32m    146\u001b[39m     warnings.filters = warning_filters\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/pyCLAD/clad_venv/lib/python3.13/site-packages/sklearn/ensemble/_bagging.py:143\u001b[39m, in \u001b[36m_parallel_build_estimators\u001b[39m\u001b[34m(n_estimators, ensemble, X, y, seeds, total_n_estimators, verbose, check_input, fit_params)\u001b[39m\n\u001b[32m    140\u001b[39m     estimator_fit = estimator.fit\n\u001b[32m    142\u001b[39m \u001b[38;5;66;03m# Draw random feature, sample indices\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m143\u001b[39m features, indices = \u001b[43m_generate_bagging_indices\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    144\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    145\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbootstrap_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    146\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    147\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    148\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    149\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    150\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    153\u001b[39m fit_params_ = fit_params.copy()\n\u001b[32m    155\u001b[39m \u001b[38;5;66;03m# TODO(SLEP6): remove if condition for unrouted sample_weight when metadata\u001b[39;00m\n\u001b[32m    156\u001b[39m \u001b[38;5;66;03m# routing can't be disabled.\u001b[39;00m\n\u001b[32m    157\u001b[39m \u001b[38;5;66;03m# 1. If routing is enabled, we will check if the routing supports sample\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    163\u001b[39m \u001b[38;5;66;03m# by indexing. The former is more efficient. Therefore, use this method\u001b[39;00m\n\u001b[32m    164\u001b[39m \u001b[38;5;66;03m# if possible, otherwise use indexing.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/pyCLAD/clad_venv/lib/python3.13/site-packages/sklearn/ensemble/_bagging.py:78\u001b[39m, in \u001b[36m_generate_bagging_indices\u001b[39m\u001b[34m(random_state, bootstrap_features, bootstrap_samples, n_features, n_samples, max_features, max_samples)\u001b[39m\n\u001b[32m     76\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Randomly draw feature and sample indices.\"\"\"\u001b[39;00m\n\u001b[32m     77\u001b[39m \u001b[38;5;66;03m# Get valid random state\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m random_state = \u001b[43mcheck_random_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[38;5;66;03m# Draw indices\u001b[39;00m\n\u001b[32m     81\u001b[39m feature_indices = _generate_indices(\n\u001b[32m     82\u001b[39m     random_state, bootstrap_features, n_features, max_features\n\u001b[32m     83\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/pyCLAD/clad_venv/lib/python3.13/site-packages/sklearn/utils/validation.py:1513\u001b[39m, in \u001b[36mcheck_random_state\u001b[39m\u001b[34m(seed)\u001b[39m\n\u001b[32m   1511\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m np.random.mtrand._rand\n\u001b[32m   1512\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(seed, numbers.Integral):\n\u001b[32m-> \u001b[39m\u001b[32m1513\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrandom\u001b[49m\u001b[43m.\u001b[49m\u001b[43mRandomState\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1514\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(seed, np.random.RandomState):\n\u001b[32m   1515\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m seed\n",
      "\u001b[36mFile \u001b[39m\u001b[32mnumpy/random/mtrand.pyx:185\u001b[39m, in \u001b[36mnumpy.random.mtrand.RandomState.__init__\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mnumpy/random/_mt19937.pyx:132\u001b[39m, in \u001b[36mnumpy.random._mt19937.MT19937.__init__\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/pyCLAD/clad_venv/lib/python3.13/site-packages/numpy/_core/_ufunc_config.py:479\u001b[39m, in \u001b[36merrstate.__call__.<locals>.inner\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    476\u001b[39m _token = _extobj_contextvar.set(extobj)\n\u001b[32m    477\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    478\u001b[39m     \u001b[38;5;66;03m# Call the original, decorated, function:\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m479\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    481\u001b[39m     _extobj_contextvar.reset(_token)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "def run_experiments():\n",
    "    for dataset_name, dataset_class in DATASETS.items():\n",
    "        for dataset_type in DATASET_TYPES:\n",
    "            print(f\"Running experiments for {dataset_name} - {dataset_type}\")\n",
    "            try:\n",
    "                dataset = dataset_class(dataset_type=dataset_type)\n",
    "            except Exception as e:\n",
    "                print(f\"Could not load dataset {dataset_name} with type {dataset_type}. Error: {e}\")\n",
    "                continue\n",
    "\n",
    "            for strategy_name, strategy_builder in STRATEGIES.items():\n",
    "                print(f\"  with strategy: {strategy_name}\")\n",
    "                model = IsolationForestAdapter()\n",
    "                strategy = strategy_builder(model)\n",
    "\n",
    "                callbacks = [\n",
    "                    ConceptMetricCallback(\n",
    "                        base_metric=RocAuc(),\n",
    "                        metrics=[ContinualAverage(), BackwardTransfer(), ForwardTransfer()]\n",
    "                    ),\n",
    "                    TimeEvaluationCallback(),\n",
    "                    MemoryUsageCallback(),\n",
    "                ]\n",
    "                scenario = ConceptAwareScenario(dataset, strategy=strategy, callbacks=callbacks)\n",
    "                scenario.run()\n",
    "\n",
    "                output_filename = f\"{dataset_name}_{dataset_type}_{strategy_name}.json\"\n",
    "                output_writer = JsonOutputWriter(RESULTS_DIR / output_filename)\n",
    "                output_writer.write([model, dataset, strategy, *callbacks])\n",
    "                print(f\"    Results saved to {output_writer._path}\")\n",
    "\n",
    "run_experiments()\n",
    "print(\"All experiments finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2d5a25",
   "metadata": {},
   "source": [
    "### Analyze Results and Generate Plots\n",
    "\n",
    "This cell analyzes the results from the experiments. For each dataset and scenario, it generates:\n",
    "1.  A heatmap of the ROC-AUC scores for each strategy individually.\n",
    "2.  A comparison heatmap showing the difference in ROC-AUC scores between the `ReplayEnhancedStrategy` and the `BalancedReservoirSamplingStrategy`.\n",
    "\n",
    "All plots are saved in the `comparison_plots` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933afc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_results():\n",
    "    for dataset_name in DATASETS.keys():\n",
    "        for dataset_type in DATASET_TYPES:\n",
    "            print(f\"Analyzing results for {dataset_name} - {dataset_type}\")\n",
    "            \n",
    "            results_files = {\n",
    "                strategy_name: RESULTS_DIR / f\"{dataset_name}_{dataset_type}_{strategy_name}.json\"\n",
    "                for strategy_name in STRATEGIES.keys()\n",
    "            }\n",
    "\n",
    "            if not all(f.exists() for f in results_files.values()):\n",
    "                print(f\"  Skipping, not all result files found for {dataset_name} - {dataset_type}\")\n",
    "                continue\n",
    "\n",
    "            dataframes = {}\n",
    "            concepts = None\n",
    "            for strategy_name, file_path in results_files.items():\n",
    "                with open(file_path, \"r\") as f:\n",
    "                    results = json.load(f)\n",
    "                \n",
    "                metric_key = next((k for k in results if k.startswith(\"concept_metric_callback\")), None)\n",
    "                if not metric_key:\n",
    "                    print(f\"  Could not find metric callback in {file_path}\")\n",
    "                    continue\n",
    "\n",
    "                metric_data = results[metric_key]\n",
    "                if concepts is None:\n",
    "                    concepts = metric_data[\"concepts_order\"]\n",
    "                matrix = metric_data[\"metric_matrix\"]\n",
    "                df = pd.DataFrame(matrix, index=concepts, columns=concepts)\n",
    "                dataframes[strategy_name] = df\n",
    "\n",
    "                # Plot individual heatmap\n",
    "                plt.figure(figsize=(8, 6))\n",
    "                sns.heatmap(df.where(np.triu(np.ones(df.shape), k=0).astype(bool)), annot=True, fmt=\".2f\", cmap=\"viridis\")\n",
    "                plt.title(f\"ROC-AUC: {dataset_name} - {dataset_type}\\\\n({strategy_name})\")\n",
    "                plt.ylabel(\"Trained Concepts\")\n",
    "                plt.xlabel(\"Testing Concepts\")\n",
    "                plt.tight_layout()\n",
    "                plot_filename = PLOTS_DIR / f\"{dataset_name}_{dataset_type}_{strategy_name}_heatmap.png\"\n",
    "                plt.savefig(plot_filename)\n",
    "                plt.close()\n",
    "                print(f\"  Saved heatmap to {plot_filename}\")\n",
    "\n",
    "            if len(dataframes) == 2:\n",
    "                # Plot comparison heatmap\n",
    "                df1 = dataframes[\"replay_enhanced\"]\n",
    "                df2 = dataframes[\"balanced_reservoir\"]\n",
    "                comparison_df = df1 - df2\n",
    "                \n",
    "                plt.figure(figsize=(8, 6))\n",
    "                sns.heatmap(comparison_df.where(np.triu(np.ones(comparison_df.shape), k=0).astype(bool)), annot=True, fmt=\".2f\", cmap=\"coolwarm\", center=0)\n",
    "                plt.title(f\"ROC-AUC Comparison: Replay Enhanced vs Balanced Reservoir\\\\n{dataset_name} - {dataset_type}\")\n",
    "                plt.ylabel(\"Trained Concepts\")\n",
    "                plt.xlabel(\"Testing Concepts\")\n",
    "                plt.tight_layout()\n",
    "                comp_plot_filename = PLOTS_DIR / f\"{dataset_name}_{dataset_type}_comparison_heatmap.png\"\n",
    "                plt.savefig(comp_plot_filename)\n",
    "                plt.close()\n",
    "                print(f\"  Saved comparison heatmap to {comp_plot_filename}\")\n",
    "\n",
    "analyze_results()\n",
    "print(\"Analysis finished. All plots are saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clad_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
