{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8658021d",
   "metadata": {},
   "source": [
    "# Comparison of Replay Strategies in pyCLAD\n",
    "\n",
    "This notebook compares the performance of `ReplayEnhancedStrategy` and `BalancedReservoirSamplingStrategy` from the `pyCLAD` library.\n",
    "The comparison is performed across four datasets: Energy, NSL-KDD, UNSW, and Wind.\n",
    "For each dataset, three different data scenarios are used: `random_anomalies`, `clustered_with_closest_assignment`, and `clustered_with_random_assignment`.\n",
    "\n",
    "The notebook is divided into three main parts:\n",
    "1.  **Setup**: Imports necessary libraries and defines the configuration for datasets, strategies, and output directories.\n",
    "2.  **Run Experiments**: Executes the experiments for each combination of dataset, scenario, and strategy, saving the results to JSON files.\n",
    "3.  **Analyze Results**: Loads the saved results, generates heatmaps for each experiment, and creates comparison heatmaps to visualize the performance difference between the two strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c359695",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/firepond/code/pyCLAD/clad_venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete.\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Datasets\n",
    "from pyclad.data.datasets.unsw_dataset import UnswDataset\n",
    "from pyclad.data.datasets.nsl_kdd_dataset import NslKddDataset\n",
    "from pyclad.data.datasets.wind_energy_dataset import WindEnergyDataset\n",
    "from pyclad.data.datasets.energy_plants_dataset import EnergyPlantsDataset\n",
    "\n",
    "# Scenarios\n",
    "from pyclad.scenarios.concept_aware import ConceptAwareScenario\n",
    "\n",
    "from pyclad.metrics.continual.average_continual import ContinualAverage\n",
    "from pyclad.metrics.continual.backward_transfer import BackwardTransfer\n",
    "from pyclad.metrics.continual.forward_transfer import ForwardTransfer\n",
    "# Models\n",
    "from pyclad.models.adapters.pyod_adapters import LocalOutlierFactorAdapter\n",
    "\n",
    "# Strategies\n",
    "from pyclad.strategies.replay.replay import ReplayEnhancedStrategy\n",
    "from pyclad.strategies.replay.watch import WatchStrategy\n",
    "\n",
    "# Additional imports for replay strategies\n",
    "from pyclad.strategies.replay.buffers.adaptive_balanced import (\n",
    "    AdaptiveBalancedReplayBuffer,\n",
    ")\n",
    "from pyclad.strategies.replay.selection.random import RandomSelection\n",
    "\n",
    "# Callback and metrics\n",
    "from pyclad.callbacks.evaluation.concept_metric_evaluation import ConceptMetricCallback\n",
    "from pyclad.callbacks.evaluation.memory_usage import MemoryUsageCallback\n",
    "from pyclad.callbacks.evaluation.time_evaluation import TimeEvaluationCallback\n",
    "from pyclad.metrics.base.roc_auc import RocAuc\n",
    "from pyclad.output.json_writer import JsonOutputWriter\n",
    "\n",
    "# Configuration\n",
    "DATASETS = {\n",
    "    \"energy\": EnergyPlantsDataset,\n",
    "    \"nsl-kdd\": NslKddDataset,\n",
    "    \"unsw\": UnswDataset,\n",
    "    \"wind\": WindEnergyDataset,\n",
    "}\n",
    "\n",
    "DATASET_TYPES = [\n",
    "    \"random_anomalies\",\n",
    "    \"clustered_with_closest_assignment\",\n",
    "    \"clustered_with_random_assignment\",\n",
    "]\n",
    "\n",
    "STRATEGIES = {\n",
    "    \"replay_enhanced\": lambda model: ReplayEnhancedStrategy(\n",
    "        model,\n",
    "        AdaptiveBalancedReplayBuffer(selection_method=RandomSelection(), max_size=3000),\n",
    "    ),\n",
    "    \"watch\": lambda model: WatchStrategy(\n",
    "        model, max_buffer_size=1000, threshold_ratio=0.1\n",
    "    ),\n",
    "}\n",
    "\n",
    "RESULTS_DIR = pathlib.Path(\"comparison_results\")\n",
    "PLOTS_DIR = pathlib.Path(\"comparison_plots\")\n",
    "RESULTS_DIR.mkdir(exist_ok=True)\n",
    "PLOTS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"Setup complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f42f85d",
   "metadata": {},
   "source": [
    "### Run Experiments\n",
    "\n",
    "The following cell runs the experiments. It iterates through each dataset and dataset type, and for each, it runs both the `ReplayEnhancedStrategy` and the `BalancedReservoirSamplingStrategy`. The results are saved in the `comparison_results` directory.\n",
    "\n",
    "**Note:** This process can be time-consuming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a73b19b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiments for energy - random_anomalies\n",
      "  with strategy: replay_enhanced\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/pyCLAD/clad_venv/lib/python3.13/site-packages/pyod/models/lof.py:213\u001b[39m, in \u001b[36mLOF.decision_function\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m213\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m invert_order(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdetector_\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_score_samples\u001b[49m(X))\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n",
      "\u001b[31mAttributeError\u001b[39m: 'LocalOutlierFactor' object has no attribute '_score_samples'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/pyCLAD/clad_venv/lib/python3.13/site-packages/pyod/models/lof.py:216\u001b[39m, in \u001b[36mLOF.decision_function\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m invert_order(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdetector_\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_decision_function\u001b[49m(X))\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n",
      "\u001b[31mAttributeError\u001b[39m: 'LocalOutlierFactor' object has no attribute '_decision_function'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 32\u001b[39m\n\u001b[32m     29\u001b[39m                 output_writer.write([model, dataset, strategy, *callbacks])\n\u001b[32m     30\u001b[39m                 \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m    Results saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_writer._path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m \u001b[43mrun_experiments\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mAll experiments finished.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 25\u001b[39m, in \u001b[36mrun_experiments\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     16\u001b[39m callbacks = [\n\u001b[32m     17\u001b[39m     ConceptMetricCallback(\n\u001b[32m     18\u001b[39m         base_metric=RocAuc(),\n\u001b[32m   (...)\u001b[39m\u001b[32m     22\u001b[39m     MemoryUsageCallback(),\n\u001b[32m     23\u001b[39m ]\n\u001b[32m     24\u001b[39m scenario = ConceptAwareScenario(dataset, strategy=strategy, callbacks=callbacks)\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m \u001b[43mscenario\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m output_filename = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstrategy_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.json\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     28\u001b[39m output_writer = JsonOutputWriter(RESULTS_DIR / output_filename)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/pyCLAD/src/pyclad/scenarios/concept_aware.py:34\u001b[39m, in \u001b[36mConceptAwareScenario.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     32\u001b[39m     logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mStarting evaluation of concept \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_concept.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     33\u001b[39m     callback_composite.before_evaluation()\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m     y_predicted, anomaly_scores = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_strategy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest_concept\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconcept_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest_concept\u001b[49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     37\u001b[39m     callback_composite.after_evaluation(\n\u001b[32m     38\u001b[39m         evaluated_concept=test_concept,\n\u001b[32m     39\u001b[39m         y_true=test_concept.labels,\n\u001b[32m     40\u001b[39m         y_pred=y_predicted,\n\u001b[32m     41\u001b[39m         anomaly_scores=anomaly_scores,\n\u001b[32m     42\u001b[39m     )\n\u001b[32m     44\u001b[39m callback_composite.after_concept_processing(concept=train_concept)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/pyCLAD/src/pyclad/strategies/replay/replay.py:43\u001b[39m, in \u001b[36mReplayEnhancedStrategy.predict\u001b[39m\u001b[34m(self, data, **kwargs)\u001b[39m\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, data: np.ndarray, **kwargs) -> (np.ndarray, np.ndarray):\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/pyCLAD/src/pyclad/models/adapters/pyod_adapters.py:21\u001b[39m, in \u001b[36mPyODAdapter.predict\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, data: np.ndarray) -> (np.ndarray, np.ndarray):\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m._model.decision_function(data)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/pyCLAD/clad_venv/lib/python3.13/site-packages/pyod/models/base.py:162\u001b[39m, in \u001b[36mBaseDetector.predict\u001b[39m\u001b[34m(self, X, return_confidence)\u001b[39m\n\u001b[32m    141\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Predict if a particular sample is an outlier or not.\u001b[39;00m\n\u001b[32m    142\u001b[39m \n\u001b[32m    143\u001b[39m \u001b[33;03mParameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    158\u001b[39m \u001b[33;03m    Only if return_confidence is set to True.\u001b[39;00m\n\u001b[32m    159\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    161\u001b[39m check_is_fitted(\u001b[38;5;28mself\u001b[39m, [\u001b[33m'\u001b[39m\u001b[33mdecision_scores_\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mthreshold_\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mlabels_\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m--> \u001b[39m\u001b[32m162\u001b[39m pred_score = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdecision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.contamination, (\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mint\u001b[39m)):\n\u001b[32m    165\u001b[39m     prediction = (pred_score > \u001b[38;5;28mself\u001b[39m.threshold_).astype(\u001b[33m'\u001b[39m\u001b[33mint\u001b[39m\u001b[33m'\u001b[39m).ravel()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/pyCLAD/clad_venv/lib/python3.13/site-packages/pyod/models/lof.py:218\u001b[39m, in \u001b[36mLOF.decision_function\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    216\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m invert_order(\u001b[38;5;28mself\u001b[39m.detector_._decision_function(X))\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m invert_order(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdetector_\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscore_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/pyCLAD/clad_venv/lib/python3.13/site-packages/sklearn/neighbors/_lof.py:476\u001b[39m, in \u001b[36mLocalOutlierFactor.score_samples\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    473\u001b[39m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m    474\u001b[39m X = check_array(X, accept_sparse=\u001b[33m\"\u001b[39m\u001b[33mcsr\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m476\u001b[39m distances_X, neighbors_indices_X = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkneighbors\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    477\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_neighbors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_neighbors_\u001b[49m\n\u001b[32m    478\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m X.dtype == np.float32:\n\u001b[32m    481\u001b[39m     distances_X = distances_X.astype(X.dtype, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/pyCLAD/clad_venv/lib/python3.13/site-packages/sklearn/neighbors/_base.py:923\u001b[39m, in \u001b[36mKNeighborsMixin.kneighbors\u001b[39m\u001b[34m(self, X, n_neighbors, return_distance)\u001b[39m\n\u001b[32m    918\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m issparse(X):\n\u001b[32m    919\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    920\u001b[39m             \u001b[33m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m does not work with sparse matrices. Densify the data, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    921\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mor set algorithm=\u001b[39m\u001b[33m'\u001b[39m\u001b[33mbrute\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m % \u001b[38;5;28mself\u001b[39m._fit_method\n\u001b[32m    922\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m923\u001b[39m     chunked_results = \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefer\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mthreads\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    924\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_tree\u001b[49m\u001b[43m.\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43ms\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_neighbors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_distance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    925\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgen_even_slices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    926\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    927\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    928\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33minternal: _fit_method not recognized\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/pyCLAD/clad_venv/lib/python3.13/site-packages/sklearn/utils/parallel.py:82\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     73\u001b[39m warning_filters = warnings.filters\n\u001b[32m     74\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     75\u001b[39m     (\n\u001b[32m     76\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     81\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/pyCLAD/clad_venv/lib/python3.13/site-packages/joblib/parallel.py:1986\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1984\u001b[39m     output = \u001b[38;5;28mself\u001b[39m._get_sequential_output(iterable)\n\u001b[32m   1985\u001b[39m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m1986\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1988\u001b[39m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[32m   1989\u001b[39m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[32m   1990\u001b[39m \u001b[38;5;66;03m# reused, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[32m   1991\u001b[39m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[32m   1992\u001b[39m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[32m   1993\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/pyCLAD/clad_venv/lib/python3.13/site-packages/joblib/parallel.py:1914\u001b[39m, in \u001b[36mParallel._get_sequential_output\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1912\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_batches += \u001b[32m1\u001b[39m\n\u001b[32m   1913\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_tasks += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1914\u001b[39m res = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1915\u001b[39m \u001b[38;5;28mself\u001b[39m.n_completed_tasks += \u001b[32m1\u001b[39m\n\u001b[32m   1916\u001b[39m \u001b[38;5;28mself\u001b[39m.print_progress()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/pyCLAD/clad_venv/lib/python3.13/site-packages/sklearn/utils/parallel.py:147\u001b[39m, in \u001b[36m_FuncWrapper.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(**config), warnings.catch_warnings():\n\u001b[32m    146\u001b[39m     warnings.filters = warning_filters\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "def run_experiments():\n",
    "    for dataset_name, dataset_class in DATASETS.items():\n",
    "        for dataset_type in DATASET_TYPES:\n",
    "            print(f\"Running experiments for {dataset_name} - {dataset_type}\")\n",
    "            try:\n",
    "                dataset = dataset_class(dataset_type=dataset_type)\n",
    "            except Exception as e:\n",
    "                print(f\"Could not load dataset {dataset_name} with type {dataset_type}. Error: {e}\")\n",
    "                continue\n",
    "\n",
    "            for strategy_name, strategy_builder in STRATEGIES.items():\n",
    "                print(f\"  with strategy: {strategy_name}\")\n",
    "                model = LocalOutlierFactorAdapter()\n",
    "                strategy = strategy_builder(model)\n",
    "\n",
    "                callbacks = [\n",
    "                    ConceptMetricCallback(\n",
    "                        base_metric=RocAuc(),\n",
    "                        metrics=[ContinualAverage(), BackwardTransfer(), ForwardTransfer()]\n",
    "                    ),\n",
    "                    TimeEvaluationCallback(),\n",
    "                    MemoryUsageCallback(),\n",
    "                ]\n",
    "                scenario = ConceptAwareScenario(dataset, strategy=strategy, callbacks=callbacks)\n",
    "                scenario.run()\n",
    "\n",
    "                output_filename = f\"{dataset_name}_{dataset_type}_{strategy_name}.json\"\n",
    "                output_writer = JsonOutputWriter(RESULTS_DIR / output_filename)\n",
    "                output_writer.write([model, dataset, strategy, *callbacks])\n",
    "                print(f\"    Results saved to {output_writer._path}\")\n",
    "\n",
    "run_experiments()\n",
    "print(\"All experiments finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2d5a25",
   "metadata": {},
   "source": [
    "### Analyze Results and Generate Plots\n",
    "\n",
    "This cell analyzes the results from the experiments. For each dataset and scenario, it generates:\n",
    "1.  A heatmap of the ROC-AUC scores for each strategy individually.\n",
    "2.  A comparison heatmap showing the difference in ROC-AUC scores between the `ReplayEnhancedStrategy` and the `BalancedReservoirSamplingStrategy`.\n",
    "\n",
    "All plots are saved in the `comparison_plots` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933afc57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing results for energy - random_anomalies\n",
      "  Saved heatmap to comparison_plots/energy_random_anomalies_replay_enhanced_heatmap.png\n",
      "  Saved heatmap to comparison_plots/energy_random_anomalies_watch_heatmap.png\n",
      "  Saved comparison heatmap to comparison_plots/energy_random_anomalies_comparison_heatmap.png\n",
      "Analyzing results for energy - clustered_with_closest_assignment\n",
      "  Saved heatmap to comparison_plots/energy_clustered_with_closest_assignment_replay_enhanced_heatmap.png\n",
      "  Saved heatmap to comparison_plots/energy_clustered_with_closest_assignment_watch_heatmap.png\n",
      "  Saved comparison heatmap to comparison_plots/energy_clustered_with_closest_assignment_comparison_heatmap.png\n",
      "Analyzing results for energy - clustered_with_random_assignment\n",
      "  Saved heatmap to comparison_plots/energy_clustered_with_random_assignment_replay_enhanced_heatmap.png\n",
      "  Saved heatmap to comparison_plots/energy_clustered_with_random_assignment_watch_heatmap.png\n",
      "  Saved comparison heatmap to comparison_plots/energy_clustered_with_random_assignment_comparison_heatmap.png\n",
      "Analyzing results for nsl-kdd - random_anomalies\n",
      "  Saved heatmap to comparison_plots/nsl-kdd_random_anomalies_replay_enhanced_heatmap.png\n",
      "  Saved heatmap to comparison_plots/nsl-kdd_random_anomalies_watch_heatmap.png\n",
      "  Saved comparison heatmap to comparison_plots/nsl-kdd_random_anomalies_comparison_heatmap.png\n",
      "Analyzing results for nsl-kdd - clustered_with_closest_assignment\n",
      "  Saved heatmap to comparison_plots/nsl-kdd_clustered_with_closest_assignment_replay_enhanced_heatmap.png\n",
      "  Saved heatmap to comparison_plots/nsl-kdd_clustered_with_closest_assignment_watch_heatmap.png\n",
      "  Saved comparison heatmap to comparison_plots/nsl-kdd_clustered_with_closest_assignment_comparison_heatmap.png\n",
      "Analyzing results for nsl-kdd - clustered_with_random_assignment\n",
      "  Saved heatmap to comparison_plots/nsl-kdd_clustered_with_random_assignment_replay_enhanced_heatmap.png\n",
      "  Saved heatmap to comparison_plots/nsl-kdd_clustered_with_random_assignment_watch_heatmap.png\n",
      "  Saved comparison heatmap to comparison_plots/nsl-kdd_clustered_with_random_assignment_comparison_heatmap.png\n",
      "Analyzing results for unsw - random_anomalies\n",
      "  Saved heatmap to comparison_plots/unsw_random_anomalies_replay_enhanced_heatmap.png\n",
      "  Saved heatmap to comparison_plots/unsw_random_anomalies_watch_heatmap.png\n",
      "  Saved comparison heatmap to comparison_plots/unsw_random_anomalies_comparison_heatmap.png\n",
      "Analyzing results for unsw - clustered_with_closest_assignment\n",
      "  Saved heatmap to comparison_plots/unsw_clustered_with_closest_assignment_replay_enhanced_heatmap.png\n",
      "  Saved heatmap to comparison_plots/unsw_clustered_with_closest_assignment_watch_heatmap.png\n",
      "  Saved comparison heatmap to comparison_plots/unsw_clustered_with_closest_assignment_comparison_heatmap.png\n",
      "Analyzing results for unsw - clustered_with_random_assignment\n",
      "  Saved heatmap to comparison_plots/unsw_clustered_with_random_assignment_replay_enhanced_heatmap.png\n",
      "  Saved heatmap to comparison_plots/unsw_clustered_with_random_assignment_watch_heatmap.png\n",
      "  Saved comparison heatmap to comparison_plots/unsw_clustered_with_random_assignment_comparison_heatmap.png\n",
      "Analyzing results for wind - random_anomalies\n",
      "  Saved heatmap to comparison_plots/wind_random_anomalies_replay_enhanced_heatmap.png\n",
      "  Saved heatmap to comparison_plots/wind_random_anomalies_watch_heatmap.png\n",
      "  Saved comparison heatmap to comparison_plots/wind_random_anomalies_comparison_heatmap.png\n",
      "Analyzing results for wind - clustered_with_closest_assignment\n",
      "  Saved heatmap to comparison_plots/wind_clustered_with_closest_assignment_replay_enhanced_heatmap.png\n",
      "  Saved heatmap to comparison_plots/wind_clustered_with_closest_assignment_watch_heatmap.png\n",
      "  Saved comparison heatmap to comparison_plots/wind_clustered_with_closest_assignment_comparison_heatmap.png\n",
      "Analyzing results for wind - clustered_with_random_assignment\n",
      "  Saved heatmap to comparison_plots/wind_clustered_with_random_assignment_replay_enhanced_heatmap.png\n",
      "  Saved heatmap to comparison_plots/wind_clustered_with_random_assignment_watch_heatmap.png\n",
      "  Saved comparison heatmap to comparison_plots/wind_clustered_with_random_assignment_comparison_heatmap.png\n",
      "Analysis finished. All plots are saved.\n"
     ]
    }
   ],
   "source": [
    "def analyze_results():\n",
    "    for dataset_name in DATASETS.keys():\n",
    "        for dataset_type in DATASET_TYPES:\n",
    "            print(f\"Analyzing results for {dataset_name} - {dataset_type}\")\n",
    "            \n",
    "            results_files = {\n",
    "                strategy_name: RESULTS_DIR / f\"{dataset_name}_{dataset_type}_{strategy_name}.json\"\n",
    "                for strategy_name in STRATEGIES.keys()\n",
    "            }\n",
    "\n",
    "            if not all(f.exists() for f in results_files.values()):\n",
    "                print(f\"  Skipping, not all result files found for {dataset_name} - {dataset_type}\")\n",
    "                continue\n",
    "\n",
    "            dataframes = {}\n",
    "            concepts = None\n",
    "            for strategy_name, file_path in results_files.items():\n",
    "                with open(file_path, \"r\") as f:\n",
    "                    results = json.load(f)\n",
    "                \n",
    "                metric_key = next((k for k in results if k.startswith(\"concept_metric_callback\")), None)\n",
    "                if not metric_key:\n",
    "                    print(f\"  Could not find metric callback in {file_path}\")\n",
    "                    continue\n",
    "\n",
    "                metric_data = results[metric_key]\n",
    "                if concepts is None:\n",
    "                    concepts = metric_data[\"concepts_order\"]\n",
    "                matrix = metric_data[\"metric_matrix\"]\n",
    "                df = pd.DataFrame(matrix, index=concepts, columns=concepts)\n",
    "                dataframes[strategy_name] = df\n",
    "\n",
    "                # Plot individual heatmap\n",
    "                plt.figure(figsize=(8, 6))\n",
    "                sns.heatmap(df.where(np.triu(np.ones(df.shape), k=0).astype(bool)), annot=True, fmt=\".2f\", cmap=\"viridis\")\n",
    "                plt.title(f\"ROC-AUC: {dataset_name} - {dataset_type}\\\\n({strategy_name})\")\n",
    "                plt.ylabel(\"Trained Concepts\")\n",
    "                plt.xlabel(\"Testing Concepts\")\n",
    "                plt.tight_layout()\n",
    "                plot_filename = PLOTS_DIR / f\"{dataset_name}_{dataset_type}_{strategy_name}_heatmap.png\"\n",
    "                plt.savefig(plot_filename)\n",
    "                plt.close()\n",
    "                print(f\"  Saved heatmap to {plot_filename}\")\n",
    "\n",
    "            if len(dataframes) == 2:\n",
    "                # Plot comparison heatmap\n",
    "                df1 = dataframes[\"replay_enhanced\"]\n",
    "                df2 = dataframes[\"watch\"]\n",
    "                comparison_df = df1 - df2\n",
    "                \n",
    "                plt.figure(figsize=(8, 6))\n",
    "                sns.heatmap(comparison_df.where(np.triu(np.ones(comparison_df.shape), k=0).astype(bool)), annot=True, fmt=\".2f\", cmap=\"coolwarm\", center=0)\n",
    "                plt.title(f\"ROC-AUC Comparison: Replay Enhanced vs Watch\\\\n{dataset_name} - {dataset_type}\")\n",
    "                plt.ylabel(\"Trained Concepts\")\n",
    "                plt.xlabel(\"Testing Concepts\")\n",
    "                plt.tight_layout()\n",
    "                comp_plot_filename = PLOTS_DIR / f\"{dataset_name}_{dataset_type}_comparison_heatmap.png\"\n",
    "                plt.savefig(comp_plot_filename)\n",
    "                plt.close()\n",
    "                print(f\"  Saved comparison heatmap to {comp_plot_filename}\")\n",
    "\n",
    "analyze_results()\n",
    "print(\"Analysis finished. All plots are saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clad_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
