{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8658021d",
   "metadata": {},
   "source": [
    "# Comparison of Replay Strategies in pyCLAD\n",
    "\n",
    "This notebook compares the performance of `ReplayEnhancedStrategy` and `BalancedReservoirSamplingStrategy` from the `pyCLAD` library.\n",
    "The comparison is performed across four datasets: Energy, NSL-KDD, UNSW, and Wind.\n",
    "For each dataset, three different data scenarios are used: `random_anomalies`, `clustered_with_closest_assignment`, and `clustered_with_random_assignment`.\n",
    "\n",
    "The notebook is divided into three main parts:\n",
    "1.  **Setup**: Imports necessary libraries and defines the configuration for datasets, strategies, and output directories.\n",
    "2.  **Run Experiments**: Executes the experiments for each combination of dataset, scenario, and strategy, saving the results to JSON files.\n",
    "3.  **Analyze Results**: Loads the saved results, generates heatmaps for each experiment, and creates comparison heatmaps to visualize the performance difference between the two strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c359695",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/firepond/development/pyCLAD/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete.\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "\n",
    "# Datasets\n",
    "from pyclad.data.datasets.unsw_dataset import UnswDataset\n",
    "from pyclad.data.datasets.nsl_kdd_dataset import NslKddDataset\n",
    "from pyclad.data.datasets.wind_energy_dataset import WindEnergyDataset\n",
    "from pyclad.data.datasets.energy_plants_dataset import EnergyPlantsDataset\n",
    "\n",
    "# Scenarios\n",
    "from pyclad.scenarios.concept_aware import ConceptAwareScenario\n",
    "\n",
    "from pyclad.metrics.continual.average_continual import ContinualAverage\n",
    "from pyclad.metrics.continual.backward_transfer import BackwardTransfer\n",
    "from pyclad.metrics.continual.forward_transfer import ForwardTransfer\n",
    "# Models\n",
    "from pyclad.models.adapters.pyod_adapters import LocalOutlierFactorAdapter\n",
    "\n",
    "# Strategies\n",
    "from pyclad.strategies.replay.replay import ReplayEnhancedStrategy\n",
    "from pyclad.strategies.replay.candi import CandiStrategy\n",
    "\n",
    "# Additional imports for replay strategies\n",
    "from pyclad.strategies.replay.buffers.adaptive_balanced import (\n",
    "    AdaptiveBalancedReplayBuffer,\n",
    ")\n",
    "from pyclad.strategies.replay.selection.random import RandomSelection\n",
    "\n",
    "# Callback and metrics\n",
    "from pyclad.callbacks.evaluation.concept_metric_evaluation import ConceptMetricCallback\n",
    "from pyclad.callbacks.evaluation.memory_usage import MemoryUsageCallback\n",
    "from pyclad.callbacks.evaluation.time_evaluation import TimeEvaluationCallback\n",
    "from pyclad.metrics.base.roc_auc import RocAuc\n",
    "from pyclad.output.json_writer import JsonOutputWriter\n",
    "import time\n",
    "\n",
    "# Configuration\n",
    "DATASETS = {\n",
    "    \"wind\": WindEnergyDataset,\n",
    "    \"unsw\": UnswDataset,\n",
    "    \"energy\": EnergyPlantsDataset,\n",
    "    \"nsl-kdd\": NslKddDataset,\n",
    "}\n",
    "\n",
    "DATASET_TYPES = [\n",
    "    \"random_anomalies\",\n",
    "    \"clustered_with_closest_assignment\",\n",
    "    \"clustered_with_random_assignment\",\n",
    "]\n",
    "\n",
    "max_size = 1000\n",
    "\n",
    "STRATEGIES = {\n",
    "    \"replay_enhanced\": lambda model: ReplayEnhancedStrategy(\n",
    "        model,\n",
    "        AdaptiveBalancedReplayBuffer(selection_method=RandomSelection(), max_size=max_size),\n",
    "    ),\n",
    "    \"watch_percentile\": lambda model: CandiStrategy(\n",
    "        model, max_buffer_size=max_size, threshold_ratio=0.5, warm_up_period=2, threshold_cal_index=1, resize_new_regime=True\n",
    "    ), \n",
    "}\n",
    "\n",
    "RESULTS_DIR = pathlib.Path(\"comparison_results\")\n",
    "PLOTS_DIR = pathlib.Path(\"comparison_plots\")\n",
    "RESULTS_DIR.mkdir(exist_ok=True)\n",
    "PLOTS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"Setup complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f42f85d",
   "metadata": {},
   "source": [
    "### Run Experiments\n",
    "\n",
    "The following cell runs the experiments. It iterates through each dataset and dataset type, and for each, it runs both the `ReplayEnhancedStrategy` and the `BalancedReservoirSamplingStrategy`. The results are saved in the `comparison_results` directory.\n",
    "\n",
    "**Note:** This process can be time-consuming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a73b19b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiments for wind - random_anomalies\n",
      "  with strategy: replay_enhanced\n",
      "Fitting model on combined data of shape: (9000, 10)\n",
      "Fitting model on combined data of shape: (7487, 10)\n",
      "Fitting model on combined data of shape: (10000, 10)\n",
      "Fitting model on combined data of shape: (9999, 10)\n",
      "Fitting model on combined data of shape: (10000, 10)\n",
      "Continual Average: 0.970691387884379\n",
      "  Time taken: 8.50 seconds\n",
      "  with strategy: watch_percentile\n",
      "Fitting model on combined data of shape: (1000, 10)\n",
      "Fitting model on combined data of shape: (2000, 10)\n",
      "Updating regime size limits.\n",
      "Buffer limit for each regime: 500\n",
      "Fitting model on combined data of shape: (2000, 10)\n",
      "Updating regime size limits.\n",
      "Buffer limit for each regime: 500\n",
      "Fitting model on combined data of shape: (2000, 10)\n",
      "Updating regime size limits.\n",
      "Buffer limit for each regime: 500\n",
      "Fitting model on combined data of shape: (2000, 10)\n",
      "Updating regime size limits.\n",
      "Buffer limit for each regime: 500\n",
      "Continual Average: 0.970000742704021\n",
      "  Time taken: 3.67 seconds\n",
      "--------------------\n",
      "Running experiments for wind - clustered_with_closest_assignment\n",
      "  with strategy: replay_enhanced\n",
      "Fitting model on combined data of shape: (3873, 10)\n",
      "Fitting model on combined data of shape: (7000, 10)\n",
      "Fitting model on combined data of shape: (4940, 10)\n",
      "Fitting model on combined data of shape: (6999, 10)\n",
      "Fitting model on combined data of shape: (3742, 10)\n",
      "Fitting model on combined data of shape: (5860, 10)\n",
      "Fitting model on combined data of shape: (4750, 10)\n",
      "Fitting model on combined data of shape: (6088, 10)\n",
      "Fitting model on combined data of shape: (5048, 10)\n",
      "Fitting model on combined data of shape: (6141, 10)\n",
      "Continual Average: 0.9448858986485851\n",
      "  Time taken: 11.65 seconds\n",
      "  with strategy: watch_percentile\n",
      "Fitting model on combined data of shape: (1000, 10)\n",
      "Fitting model on combined data of shape: (2000, 10)\n",
      "Updating regime size limits.\n",
      "Buffer limit for each regime: 500\n",
      "Fitting model on combined data of shape: (2000, 10)\n",
      "Updating regime size limits.\n",
      "Buffer limit for each regime: 500\n",
      "Fitting model on combined data of shape: (2000, 10)\n",
      "Updating regime size limits.\n",
      "Buffer limit for each regime: 500\n",
      "Fitting model on combined data of shape: (2000, 10)\n",
      "Updating regime size limits.\n",
      "Buffer limit for each regime: 500\n",
      "Fitting model on combined data of shape: (2000, 10)\n",
      "Updating regime size limits.\n",
      "Buffer limit for each regime: 500\n",
      "Fitting model on combined data of shape: (2000, 10)\n",
      "Updating regime size limits.\n",
      "Buffer limit for each regime: 500\n",
      "Fitting model on combined data of shape: (2000, 10)\n",
      "Updating regime size limits.\n",
      "Buffer limit for each regime: 500\n",
      "Fitting model on combined data of shape: (2000, 10)\n",
      "Updating regime size limits.\n",
      "Buffer limit for each regime: 500\n",
      "Fitting model on combined data of shape: (2000, 10)\n",
      "Updating regime size limits.\n",
      "Buffer limit for each regime: 500\n",
      "Continual Average: 0.9241521712248812\n",
      "  Time taken: 7.22 seconds\n",
      "--------------------\n",
      "Running experiments for wind - clustered_with_random_assignment\n",
      "  with strategy: replay_enhanced\n",
      "Fitting model on combined data of shape: (9000, 10)\n",
      "Fitting model on combined data of shape: (7487, 10)\n",
      "Fitting model on combined data of shape: (10000, 10)\n",
      "Fitting model on combined data of shape: (9999, 10)\n",
      "Fitting model on combined data of shape: (10000, 10)\n",
      "Continual Average: 0.960193608883838\n",
      "  Time taken: 8.32 seconds\n",
      "  with strategy: watch_percentile\n",
      "Fitting model on combined data of shape: (1000, 10)\n",
      "Fitting model on combined data of shape: (2000, 10)\n",
      "Updating regime size limits.\n",
      "Buffer limit for each regime: 500\n",
      "Fitting model on combined data of shape: (2000, 10)\n",
      "Updating regime size limits.\n",
      "Buffer limit for each regime: 500\n",
      "Fitting model on combined data of shape: (2000, 10)\n",
      "Updating regime size limits.\n",
      "Buffer limit for each regime: 500\n",
      "Fitting model on combined data of shape: (2000, 10)\n",
      "Updating regime size limits.\n",
      "Buffer limit for each regime: 500\n",
      "Continual Average: 0.9546074476069205\n",
      "  Time taken: 3.60 seconds\n",
      "--------------------\n",
      "Finished experiments for wind.\n",
      "========================================\n",
      "Running experiments for unsw - random_anomalies\n",
      "  with strategy: replay_enhanced\n",
      "Fitting model on combined data of shape: (15162, 43)\n",
      "Fitting model on combined data of shape: (9269, 43)\n",
      "Fitting model on combined data of shape: (16908, 43)\n",
      "Fitting model on combined data of shape: (10654, 43)\n",
      "Fitting model on combined data of shape: (7649, 43)\n",
      "Fitting model on combined data of shape: (9099, 43)\n",
      "Fitting model on combined data of shape: (3199, 43)\n",
      "Fitting model on combined data of shape: (2498, 43)\n",
      "Fitting model on combined data of shape: (9074, 43)\n",
      "Fitting model on combined data of shape: (8469, 43)\n",
      "Continual Average: 0.7539448531728122\n",
      "  Time taken: 19.11 seconds\n",
      "  with strategy: watch_percentile\n",
      "Fitting model on combined data of shape: (1000, 43)\n",
      "Fitting model on combined data of shape: (2000, 43)\n",
      "Updating regime size limits.\n",
      "Buffer limit for each regime: 500\n",
      "Fitting model on combined data of shape: (2000, 43)\n",
      "Updating regime size limits.\n",
      "Buffer limit for each regime: 500\n",
      "Fitting model on combined data of shape: (2000, 43)\n",
      "Updating regime size limits.\n",
      "Buffer limit for each regime: 500\n",
      "Fitting model on combined data of shape: (2000, 43)\n",
      "Updating regime size limits.\n",
      "Buffer limit for each regime: 500\n",
      "Fitting model on combined data of shape: (2000, 43)\n",
      "Updating regime size limits.\n",
      "Buffer limit for each regime: 500\n",
      "Fitting model on combined data of shape: (2000, 43)\n",
      "Updating regime size limits.\n",
      "Buffer limit for each regime: 500\n",
      "Fitting model on combined data of shape: (2000, 43)\n",
      "Updating regime size limits.\n",
      "Buffer limit for each regime: 500\n",
      "Fitting model on combined data of shape: (2000, 43)\n",
      "Updating regime size limits.\n",
      "Buffer limit for each regime: 500\n",
      "Fitting model on combined data of shape: (2000, 43)\n",
      "Updating regime size limits.\n",
      "Buffer limit for each regime: 500\n",
      "Continual Average: 0.8048374421279901\n",
      "  Time taken: 6.06 seconds\n",
      "--------------------\n",
      "Running experiments for unsw - clustered_with_closest_assignment\n",
      "  with strategy: replay_enhanced\n",
      "Fitting model on combined data of shape: (15162, 43)\n",
      "Fitting model on combined data of shape: (9269, 43)\n",
      "Fitting model on combined data of shape: (16908, 43)\n",
      "Fitting model on combined data of shape: (10654, 43)\n",
      "Fitting model on combined data of shape: (7649, 43)\n",
      "Fitting model on combined data of shape: (9099, 43)\n",
      "Fitting model on combined data of shape: (3199, 43)\n",
      "Fitting model on combined data of shape: (2498, 43)\n",
      "Fitting model on combined data of shape: (9074, 43)\n",
      "Fitting model on combined data of shape: (8469, 43)\n",
      "Continual Average: 0.7550482189694752\n",
      "  Time taken: 18.08 seconds\n",
      "  with strategy: watch_percentile\n",
      "Fitting model on combined data of shape: (1000, 43)\n",
      "Fitting model on combined data of shape: (2000, 43)\n",
      "Updating regime size limits.\n",
      "Buffer limit for each regime: 500\n",
      "Fitting model on combined data of shape: (2000, 43)\n",
      "Updating regime size limits.\n",
      "Buffer limit for each regime: 500\n",
      "Fitting model on combined data of shape: (2000, 43)\n",
      "Updating regime size limits.\n",
      "Buffer limit for each regime: 500\n",
      "Fitting model on combined data of shape: (2000, 43)\n",
      "Updating regime size limits.\n",
      "Buffer limit for each regime: 500\n",
      "Fitting model on combined data of shape: (2000, 43)\n",
      "Updating regime size limits.\n",
      "Buffer limit for each regime: 500\n",
      "Fitting model on combined data of shape: (2000, 43)\n",
      "Updating regime size limits.\n",
      "Buffer limit for each regime: 500\n",
      "Fitting model on combined data of shape: (2000, 43)\n",
      "Updating regime size limits.\n",
      "Buffer limit for each regime: 500\n",
      "Fitting model on combined data of shape: (2000, 43)\n",
      "Updating regime size limits.\n",
      "Buffer limit for each regime: 500\n",
      "Fitting model on combined data of shape: (2000, 43)\n",
      "Updating regime size limits.\n",
      "Buffer limit for each regime: 500\n",
      "Continual Average: 0.7854783119092662\n",
      "  Time taken: 5.84 seconds\n",
      "--------------------\n",
      "Running experiments for unsw - clustered_with_random_assignment\n",
      "  with strategy: replay_enhanced\n",
      "Fitting model on combined data of shape: (15162, 43)\n",
      "Fitting model on combined data of shape: (9269, 43)\n",
      "Fitting model on combined data of shape: (16908, 43)\n",
      "Fitting model on combined data of shape: (10654, 43)\n",
      "Fitting model on combined data of shape: (7649, 43)\n",
      "Fitting model on combined data of shape: (9099, 43)\n",
      "Fitting model on combined data of shape: (3199, 43)\n",
      "Fitting model on combined data of shape: (2498, 43)\n",
      "Fitting model on combined data of shape: (9074, 43)\n",
      "Fitting model on combined data of shape: (8469, 43)\n",
      "Continual Average: 0.8059286823770901\n",
      "  Time taken: 18.18 seconds\n",
      "  with strategy: watch_percentile\n",
      "Fitting model on combined data of shape: (1000, 43)\n",
      "Fitting model on combined data of shape: (2000, 43)\n",
      "Updating regime size limits.\n",
      "Buffer limit for each regime: 500\n",
      "Fitting model on combined data of shape: (2000, 43)\n",
      "Updating regime size limits.\n",
      "Buffer limit for each regime: 500\n",
      "Fitting model on combined data of shape: (2000, 43)\n",
      "Updating regime size limits.\n",
      "Buffer limit for each regime: 500\n",
      "Fitting model on combined data of shape: (2000, 43)\n",
      "Updating regime size limits.\n",
      "Buffer limit for each regime: 500\n",
      "Fitting model on combined data of shape: (2000, 43)\n",
      "Updating regime size limits.\n",
      "Buffer limit for each regime: 500\n",
      "Fitting model on combined data of shape: (2000, 43)\n",
      "Updating regime size limits.\n",
      "Buffer limit for each regime: 500\n",
      "Fitting model on combined data of shape: (2000, 43)\n",
      "Updating regime size limits.\n",
      "Buffer limit for each regime: 500\n",
      "Fitting model on combined data of shape: (2000, 43)\n",
      "Updating regime size limits.\n",
      "Buffer limit for each regime: 500\n",
      "Fitting model on combined data of shape: (2000, 43)\n",
      "Updating regime size limits.\n",
      "Buffer limit for each regime: 500\n",
      "Continual Average: 0.8813494892045882\n",
      "  Time taken: 5.84 seconds\n",
      "--------------------\n",
      "Finished experiments for unsw.\n",
      "========================================\n",
      "Running experiments for energy - random_anomalies\n",
      "  with strategy: replay_enhanced\n",
      "Fitting model on combined data of shape: (6000, 14)\n",
      "Fitting model on combined data of shape: (7000, 14)\n",
      "Fitting model on combined data of shape: (7000, 14)\n",
      "Fitting model on combined data of shape: (6999, 14)\n",
      "Fitting model on combined data of shape: (7000, 14)\n",
      "Fitting model on combined data of shape: (7000, 14)\n",
      "Fitting model on combined data of shape: (6996, 14)\n",
      "Fitting model on combined data of shape: (6994, 14)\n",
      "Fitting model on combined data of shape: (7000, 14)\n",
      "Fitting model on combined data of shape: (6999, 14)\n",
      "Continual Average: 0.9563276724365751\n",
      "  Time taken: 25.79 seconds\n",
      "  with strategy: watch_percentile\n",
      "Fitting model on combined data of shape: (1000, 14)\n",
      "Fitting model on combined data of shape: (2000, 14)\n",
      "Updating regime size limits.\n",
      "Buffer limit for each regime: 500\n",
      "Fitting model on combined data of shape: (2000, 14)\n",
      "Updating regime size limits.\n",
      "Buffer limit for each regime: 500\n",
      "Fitting model on combined data of shape: (2000, 14)\n",
      "Updating regime size limits.\n",
      "Buffer limit for each regime: 500\n",
      "Fitting model on combined data of shape: (2000, 14)\n",
      "Updating regime size limits.\n",
      "Buffer limit for each regime: 500\n",
      "Fitting model on combined data of shape: (2000, 14)\n",
      "Updating regime size limits.\n",
      "Buffer limit for each regime: 500\n",
      "Fitting model on combined data of shape: (2000, 14)\n",
      "Updating regime size limits.\n",
      "Buffer limit for each regime: 500\n",
      "Fitting model on combined data of shape: (2000, 14)\n",
      "Updating regime size limits.\n",
      "Buffer limit for each regime: 500\n",
      "Fitting model on combined data of shape: (2000, 14)\n",
      "Updating regime size limits.\n",
      "Buffer limit for each regime: 500\n",
      "Fitting model on combined data of shape: (2000, 14)\n",
      "Updating regime size limits.\n",
      "Buffer limit for each regime: 500\n",
      "Continual Average: 0.9201547370507399\n",
      "  Time taken: 14.06 seconds\n",
      "--------------------\n",
      "Running experiments for energy - clustered_with_closest_assignment\n",
      "  with strategy: replay_enhanced\n",
      "Fitting model on combined data of shape: (6000, 14)\n",
      "Fitting model on combined data of shape: (7000, 14)\n",
      "Fitting model on combined data of shape: (7000, 14)\n",
      "Fitting model on combined data of shape: (6999, 14)\n",
      "Fitting model on combined data of shape: (7000, 14)\n",
      "Fitting model on combined data of shape: (7000, 14)\n",
      "Fitting model on combined data of shape: (6996, 14)\n",
      "Fitting model on combined data of shape: (6994, 14)\n",
      "Fitting model on combined data of shape: (7000, 14)\n",
      "Fitting model on combined data of shape: (6999, 14)\n",
      "Continual Average: 0.9209657540251942\n",
      "  Time taken: 24.81 seconds\n",
      "  with strategy: watch_percentile\n",
      "Fitting model on combined data of shape: (1000, 14)\n",
      "Fitting model on combined data of shape: (2000, 14)\n",
      "Updating regime size limits.\n",
      "Buffer limit for each regime: 500\n",
      "Fitting model on combined data of shape: (2000, 14)\n",
      "Updating regime size limits.\n",
      "Buffer limit for each regime: 500\n",
      "Fitting model on combined data of shape: (2000, 14)\n",
      "Updating regime size limits.\n",
      "Buffer limit for each regime: 500\n",
      "Fitting model on combined data of shape: (2000, 14)\n",
      "Updating regime size limits.\n",
      "Buffer limit for each regime: 500\n",
      "Fitting model on combined data of shape: (2000, 14)\n",
      "Updating regime size limits.\n",
      "Buffer limit for each regime: 500\n",
      "Fitting model on combined data of shape: (2000, 14)\n",
      "Updating regime size limits.\n",
      "Buffer limit for each regime: 500\n",
      "Fitting model on combined data of shape: (2000, 14)\n",
      "Updating regime size limits.\n",
      "Buffer limit for each regime: 500\n",
      "Fitting model on combined data of shape: (2000, 14)\n",
      "Updating regime size limits.\n",
      "Buffer limit for each regime: 500\n",
      "Fitting model on combined data of shape: (2000, 14)\n",
      "Updating regime size limits.\n",
      "Buffer limit for each regime: 500\n",
      "Continual Average: 0.873667084281973\n",
      "  Time taken: 13.91 seconds\n",
      "--------------------\n",
      "Running experiments for energy - clustered_with_random_assignment\n",
      "  with strategy: replay_enhanced\n",
      "Fitting model on combined data of shape: (6000, 14)\n",
      "Fitting model on combined data of shape: (7000, 14)\n",
      "Fitting model on combined data of shape: (7000, 14)\n",
      "Fitting model on combined data of shape: (6999, 14)\n",
      "Fitting model on combined data of shape: (7000, 14)\n",
      "Fitting model on combined data of shape: (7000, 14)\n",
      "Fitting model on combined data of shape: (6996, 14)\n",
      "Fitting model on combined data of shape: (6994, 14)\n",
      "Fitting model on combined data of shape: (7000, 14)\n",
      "Fitting model on combined data of shape: (6999, 14)\n",
      "Continual Average: 0.9416661609820987\n",
      "  Time taken: 24.77 seconds\n",
      "  with strategy: watch_percentile\n",
      "Fitting model on combined data of shape: (1000, 14)\n",
      "Fitting model on combined data of shape: (2000, 14)\n",
      "Updating regime size limits.\n",
      "Buffer limit for each regime: 500\n",
      "Fitting model on combined data of shape: (2000, 14)\n",
      "Updating regime size limits.\n",
      "Buffer limit for each regime: 500\n",
      "Fitting model on combined data of shape: (2000, 14)\n",
      "Updating regime size limits.\n",
      "Buffer limit for each regime: 500\n",
      "Fitting model on combined data of shape: (2000, 14)\n",
      "Updating regime size limits.\n",
      "Buffer limit for each regime: 500\n",
      "Fitting model on combined data of shape: (2000, 14)\n",
      "Updating regime size limits.\n",
      "Buffer limit for each regime: 500\n",
      "Fitting model on combined data of shape: (2000, 14)\n",
      "Updating regime size limits.\n",
      "Buffer limit for each regime: 500\n",
      "Fitting model on combined data of shape: (2000, 14)\n",
      "Updating regime size limits.\n",
      "Buffer limit for each regime: 500\n",
      "Fitting model on combined data of shape: (2000, 14)\n",
      "Updating regime size limits.\n",
      "Buffer limit for each regime: 500\n",
      "Fitting model on combined data of shape: (2000, 14)\n",
      "Updating regime size limits.\n",
      "Buffer limit for each regime: 500\n",
      "Continual Average: 0.8662003532204351\n",
      "  Time taken: 13.55 seconds\n",
      "--------------------\n",
      "Finished experiments for energy.\n",
      "========================================\n",
      "Running experiments for nsl-kdd - random_anomalies\n",
      "  with strategy: replay_enhanced\n",
      "Fitting model on combined data of shape: (352, 41)\n",
      "Fitting model on combined data of shape: (2231, 41)\n",
      "Fitting model on combined data of shape: (3852, 41)\n",
      "Fitting model on combined data of shape: (3999, 41)\n",
      "Fitting model on combined data of shape: (1926, 41)\n",
      "Fitting model on combined data of shape: (1720, 41)\n",
      "Fitting model on combined data of shape: (2575, 41)\n",
      "Fitting model on combined data of shape: (2445, 41)\n",
      "Fitting model on combined data of shape: (4000, 41)\n",
      "Fitting model on combined data of shape: (2350, 41)\n",
      "Fitting model on combined data of shape: (1451, 41)\n",
      "Fitting model on combined data of shape: (1476, 41)\n",
      "Fitting model on combined data of shape: (2194, 41)\n",
      "Fitting model on combined data of shape: (2593, 41)\n",
      "Fitting model on combined data of shape: (2876, 41)\n",
      "Fitting model on combined data of shape: (1519, 41)\n",
      "Fitting model on combined data of shape: (1248, 41)\n",
      "Fitting model on combined data of shape: (3986, 41)\n",
      "Fitting model on combined data of shape: (2778, 41)\n",
      "Fitting model on combined data of shape: (3315, 41)\n",
      "Continual Average: 0.8885401660975701\n",
      "  Time taken: 8.34 seconds\n",
      "  with strategy: watch_percentile\n",
      "Fitting model on combined data of shape: (352, 41)\n",
      "Fitting model on combined data of shape: (1352, 41)\n",
      "Updating regime size limits.\n",
      "Buffer limit for each regime: 500\n",
      "Fitting model on combined data of shape: (1852, 41)\n",
      "Updating regime size limits.\n",
      "Buffer limit for each regime: 500\n",
      "Fitting model on combined data of shape: (2000, 41)\n",
      "Updating regime size limits.\n",
      "Buffer limit for each regime: 500\n",
      "Fitting model on combined data of shape: (1926, 41)\n",
      "Updating regime size limits.\n",
      "Buffer limit for each regime: 500\n",
      "Fitting model on combined data of shape: (1720, 41)\n",
      "Updating regime size limits.\n",
      "Buffer limit for each regime: 500\n",
      "Fitting model on combined data of shape: (2000, 41)\n",
      "Updating regime size limits.\n",
      "Buffer limit for each regime: 500\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/development/pyCLAD/.venv/lib/python3.13/site-packages/pyod/models/lof.py:213\u001b[39m, in \u001b[36mLOF.decision_function\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m213\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m invert_order(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdetector_\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_score_samples\u001b[49m(X))\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n",
      "\u001b[31mAttributeError\u001b[39m: 'LocalOutlierFactor' object has no attribute '_score_samples'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/development/pyCLAD/.venv/lib/python3.13/site-packages/pyod/models/lof.py:216\u001b[39m, in \u001b[36mLOF.decision_function\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m invert_order(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdetector_\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_decision_function\u001b[49m(X))\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n",
      "\u001b[31mAttributeError\u001b[39m: 'LocalOutlierFactor' object has no attribute '_decision_function'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 37\u001b[39m\n\u001b[32m     34\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFinished experiments for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     35\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m40\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m \u001b[43mrun_experiments\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mAll experiments finished.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 26\u001b[39m, in \u001b[36mrun_experiments\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     17\u001b[39m callbacks = [\n\u001b[32m     18\u001b[39m     ConceptMetricCallback(\n\u001b[32m     19\u001b[39m         base_metric=RocAuc(),\n\u001b[32m   (...)\u001b[39m\u001b[32m     23\u001b[39m     MemoryUsageCallback(),\n\u001b[32m     24\u001b[39m ]\n\u001b[32m     25\u001b[39m scenario = ConceptAwareScenario(dataset, strategy=strategy, callbacks=callbacks)\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m \u001b[43mscenario\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m callbacks[\u001b[32m0\u001b[39m].print_continual_average()\n\u001b[32m     29\u001b[39m end_time = time.time()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/development/pyCLAD/src/pyclad/scenarios/concept_aware.py:39\u001b[39m, in \u001b[36mConceptAwareScenario.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     37\u001b[39m     logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mStarting evaluation of concept \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_concept.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     38\u001b[39m     callback_composite.before_evaluation()\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m     y_predicted, anomaly_scores = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_strategy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest_concept\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconcept_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest_concept\u001b[49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     42\u001b[39m     callback_composite.after_evaluation(\n\u001b[32m     43\u001b[39m         evaluated_concept=test_concept,\n\u001b[32m     44\u001b[39m         y_true=test_concept.labels,\n\u001b[32m     45\u001b[39m         y_pred=y_predicted,\n\u001b[32m     46\u001b[39m         anomaly_scores=anomaly_scores,\n\u001b[32m     47\u001b[39m     )\n\u001b[32m     49\u001b[39m callback_composite.after_concept_processing(concept=train_concept)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/development/pyCLAD/src/pyclad/strategies/replay/candi.py:484\u001b[39m, in \u001b[36mCandiStrategy.predict\u001b[39m\u001b[34m(self, data, *_args, **_kwargs)\u001b[39m\n\u001b[32m    470\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpredict\u001b[39m(\n\u001b[32m    471\u001b[39m     \u001b[38;5;28mself\u001b[39m, data: np.ndarray, *_args, **_kwargs\n\u001b[32m    472\u001b[39m ) -> Tuple[np.ndarray, np.ndarray]:\n\u001b[32m    473\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    474\u001b[39m \u001b[33;03m    Make predictions on the data.\u001b[39;00m\n\u001b[32m    475\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    482\u001b[39m \u001b[33;03m        Tuple[np.ndarray, np.ndarray]: Predictions and anomaly scores.\u001b[39;00m\n\u001b[32m    483\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m484\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/development/pyCLAD/src/pyclad/models/adapters/pyod_adapters.py:21\u001b[39m, in \u001b[36mPyODAdapter.predict\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, data: np.ndarray) -> (np.ndarray, np.ndarray):\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._model.predict(data), \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/development/pyCLAD/.venv/lib/python3.13/site-packages/pyod/models/lof.py:218\u001b[39m, in \u001b[36mLOF.decision_function\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    216\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m invert_order(\u001b[38;5;28mself\u001b[39m.detector_._decision_function(X))\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m invert_order(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdetector_\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscore_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/development/pyCLAD/.venv/lib/python3.13/site-packages/sklearn/neighbors/_lof.py:474\u001b[39m, in \u001b[36mLocalOutlierFactor.score_samples\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    447\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Opposite of the Local Outlier Factor of X.\u001b[39;00m\n\u001b[32m    448\u001b[39m \n\u001b[32m    449\u001b[39m \u001b[33;03mIt is the opposite as bigger is better, i.e. large values correspond\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    471\u001b[39m \u001b[33;03m    The lower, the more abnormal.\u001b[39;00m\n\u001b[32m    472\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    473\u001b[39m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m474\u001b[39m X = \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcsr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    476\u001b[39m distances_X, neighbors_indices_X = \u001b[38;5;28mself\u001b[39m.kneighbors(\n\u001b[32m    477\u001b[39m     X, n_neighbors=\u001b[38;5;28mself\u001b[39m.n_neighbors_\n\u001b[32m    478\u001b[39m )\n\u001b[32m    480\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m X.dtype == np.float32:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/development/pyCLAD/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:1105\u001b[39m, in \u001b[36mcheck_array\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1099\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1100\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFound array with dim \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marray.ndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1101\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m while dim <= 2 is required\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcontext\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1102\u001b[39m     )\n\u001b[32m   1104\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ensure_all_finite:\n\u001b[32m-> \u001b[39m\u001b[32m1105\u001b[39m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1106\u001b[39m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1107\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1108\u001b[39m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1109\u001b[39m \u001b[43m        \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mallow-nan\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1110\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1112\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[32m   1113\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[32m   1114\u001b[39m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/development/pyCLAD/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:116\u001b[39m, in \u001b[36m_assert_all_finite\u001b[39m\u001b[34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;66;03m# First try an O(n) time, O(1) space solution for the common case that\u001b[39;00m\n\u001b[32m    112\u001b[39m \u001b[38;5;66;03m# everything is finite; fall back to O(n) space `np.isinf/isnan` or custom\u001b[39;00m\n\u001b[32m    113\u001b[39m \u001b[38;5;66;03m# Cython implementation to prevent false positives and provide a detailed\u001b[39;00m\n\u001b[32m    114\u001b[39m \u001b[38;5;66;03m# error message.\u001b[39;00m\n\u001b[32m    115\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m np.errstate(over=\u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m     first_pass_isfinite = xp.isfinite(\u001b[43mxp\u001b[49m\u001b[43m.\u001b[49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    117\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[32m    118\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/development/pyCLAD/.venv/lib/python3.13/site-packages/numpy/_core/fromnumeric.py:2466\u001b[39m, in \u001b[36msum\u001b[39m\u001b[34m(a, axis, dtype, out, keepdims, initial, where)\u001b[39m\n\u001b[32m   2463\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[32m   2464\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m res\n\u001b[32m-> \u001b[39m\u001b[32m2466\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapreduction\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2467\u001b[39m \u001b[43m    \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msum\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2468\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[43m=\u001b[49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwhere\u001b[49m\n\u001b[32m   2469\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/development/pyCLAD/.venv/lib/python3.13/site-packages/numpy/_core/fromnumeric.py:86\u001b[39m, in \u001b[36m_wrapreduction\u001b[39m\u001b[34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[39m\n\u001b[32m     83\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     84\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m reduction(axis=axis, out=out, **passkwargs)\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mufunc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpasskwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "def run_experiments():\n",
    "    for dataset_name, dataset_class in DATASETS.items():\n",
    "        for dataset_type in DATASET_TYPES:\n",
    "            print(f\"Running experiments for {dataset_name} - {dataset_type}\")\n",
    "            try:\n",
    "                dataset = dataset_class(dataset_type=dataset_type)\n",
    "            except Exception as e:\n",
    "                print(f\"Could not load dataset {dataset_name} with type {dataset_type}. Error: {e}\")\n",
    "                continue\n",
    "\n",
    "            for strategy_name, strategy_builder in STRATEGIES.items():\n",
    "                start_time = time.time()\n",
    "                print(f\"  with strategy: {strategy_name}\")\n",
    "                model = LocalOutlierFactorAdapter()\n",
    "                strategy = strategy_builder(model)\n",
    "\n",
    "                callbacks = [\n",
    "                    ConceptMetricCallback(\n",
    "                        base_metric=RocAuc(),\n",
    "                        metrics=[ContinualAverage(), BackwardTransfer(), ForwardTransfer()]\n",
    "                    ),\n",
    "                    TimeEvaluationCallback(),\n",
    "                    MemoryUsageCallback(),\n",
    "                ]\n",
    "                scenario = ConceptAwareScenario(dataset, strategy=strategy, callbacks=callbacks)\n",
    "                scenario.run()\n",
    "\n",
    "                callbacks[0].print_continual_average()\n",
    "                end_time = time.time()\n",
    "                print(f\"  Time taken: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "            print(\"-\" * 20)\n",
    "            \n",
    "        print(f\"Finished experiments for {dataset_name}.\")\n",
    "        print(\"=\" * 40)\n",
    "\n",
    "run_experiments()\n",
    "print(\"All experiments finished.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyclad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
